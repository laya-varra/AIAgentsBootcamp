{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6e6e71a",
   "metadata": {},
   "source": [
    "# ðŸ“š Lecture 2: Introduction to Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "In this notebook, we'll explore how **RAG (Retrieval-Augmented Generation)** allows GPT-4 to provide more accurate and grounded answers by retrieving relevant documents before generating a response.\n",
    "\n",
    "We'll first see how GPT-4 responds without external knowledge, then enhance the response using a document retriever with **LangChain**, **FAISS**, and **OpenAI Embeddings**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f336b704",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model='gpt-4',\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601b414b",
   "metadata": {},
   "source": [
    "## ðŸ¤– Step 2: Ask GPT-4 Without RAG\n",
    "\n",
    "Letâ€™s see how GPT-4 answers when we ask a question **without providing any documents**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb70d162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='LangChain is used for language translation. It is a decentralized translation solution that uses blockchain technology and artificial intelligence to provide high-quality translation services. It aims to eliminate intermediaries in the translation process, reduce costs, and increase efficiency. The platform also allows translators to be rewarded for their work with LangChain tokens.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 14, 'total_tokens': 77, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-b5324c37-6ac2-4a3b-8421-75b093cfaae3-0' usage_metadata={'input_tokens': 14, 'output_tokens': 63, 'total_tokens': 77, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Question not grounded in a document\n",
    "question = \"What is LangChain used for?\"\n",
    "print(llm.invoke(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feff8b8b",
   "metadata": {},
   "source": [
    "## ðŸ§  Step 3: Add External Knowledge with RAG\n",
    "\n",
    "Weâ€™ll now index a short document and use **RetrievalQA** to feed that document contextually to GPT-4 before it answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ccd053a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample docs\n",
    "docs = [\n",
    "    \"LangChain is an open-source framework that helps developers build applications powered by language models.\",\n",
    "    \"It enables agents to interact with tools, memory, and external data sources.\",\n",
    "    \"LangChain supports Retrieval-Augmented Generation to improve answer accuracy.\"\n",
    "]\n",
    "\n",
    "embeddings = OpenAIEmbeddings(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "vectorstore = FAISS.from_texts(docs, embeddings)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc86d66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\praga\\AppData\\Local\\Temp\\ipykernel_23532\\1926381149.py:9: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = qa_chain.run(question)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is used to help developers build applications that are powered by language models. It supports Retrieval-Augmented Generation to improve answer accuracy and enables agents to interact with tools, memory, and external data sources.\n"
     ]
    }
   ],
   "source": [
    "# Setup RetrievalQA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\"\n",
    ")\n",
    "\n",
    "# Ask the same question again\n",
    "response = qa_chain.run(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db08ea9",
   "metadata": {},
   "source": [
    "## âœ… Conclusion\n",
    "With RAG, GPT-4 has access to **your specific knowledge**, which improves accuracy and reduces hallucinations.\n",
    "\n",
    "**RAG = Retrieval + Generation** â€” a powerful way to make AI context-aware.\n",
    "\n",
    "In the next lecture, weâ€™ll scale this further using larger document sets, error handling, and advanced search."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
