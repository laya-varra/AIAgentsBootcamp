{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e672f92",
   "metadata": {},
   "source": [
    "# ðŸ“š Lecture 2: Introduction to Retrieval-Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5901cd",
   "metadata": {},
   "source": [
    "In this lecture, weâ€™ll explore the concept of Retrieval-Augmented Generation (RAG).\n",
    "\n",
    "RAG lets your agent pull in external informationâ€”like documents or notesâ€”before answering.\n",
    "\n",
    "Weâ€™ll use LangChainâ€™s basic memory approach to simulate a document retrieval setup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaab513",
   "metadata": {},
   "source": [
    "## ðŸ”§ Step 1: Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5a489b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "llm = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ca8663",
   "metadata": {},
   "source": [
    "## ðŸ“„ Step 2: Simulate Document Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2534d713",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_content = \"The capital of France is Paris.\"\n",
    "query = f\"With this info: {doc_content}, whatâ€™s the capital of France?\"\n",
    "print(llm(query))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
