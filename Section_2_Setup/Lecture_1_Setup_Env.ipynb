{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd22ef2f",
   "metadata": {},
   "source": [
    "# Lecture 1: Setting up Python & Development Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd97608",
   "metadata": {},
   "source": [
    "\n",
    "Welcome to **Lecture 1** of the *AI Agents Bootcamp: Build and Deploy Workflow Automation*!  \n",
    "In this notebook, you'll set up everything needed to start building your AI Agents — including Python, virtual environments, required libraries, and Jupyter Notebooks.\n",
    "\n",
    "We'll walk through the following steps:\n",
    "1. ✅ Install Python\n",
    "2. ✅ Create a virtual environment\n",
    "3. ✅ Install LangChain, Langflow, and Jupyter\n",
    "4. ✅ Install dotenv and setup `.env` securely\n",
    "5. ✅ Launch VS Code and open your notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0415896",
   "metadata": {},
   "source": [
    "\n",
    "### 🐍 Step 1: Install Python\n",
    "\n",
    "Download and install the latest version of Python from [https://www.python.org/downloads/](https://www.python.org/downloads/).\n",
    "\n",
    "Make sure to check ✅ **Add Python to PATH** during installation!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58895af",
   "metadata": {},
   "source": [
    "### 🛠️ Step 2: Create and activate a virtual environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d433ef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Windows\n",
    "# python -m venv myenv\n",
    "# myenv\\Scripts\\activate\n",
    "\n",
    "# Mac/Linux\n",
    "# python3 -m venv myenv\n",
    "# source myenv/bin/activate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe33a7f",
   "metadata": {},
   "source": [
    "\n",
    "## ✅ Step 3: Install Required Packages\n",
    "\n",
    "You have **two options**:\n",
    "\n",
    "### 🔹 Option 1: Install using `requirements.txt` (Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8946b3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langflow (from -r requirements.txt (line 1))\n",
      "  Using cached langflow-1.2.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from -r requirements.txt (line 2)) (1.0.1)\n",
      "Requirement already satisfied: jupyter in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from -r requirements.txt (line 3)) (1.1.1)\n",
      "Collecting ag2>=0.1.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached ag2-0.8.3-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting aiofile<4.0.0,>=3.9.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached aiofile-3.9.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting apify-client>=1.8.1 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached apify_client-1.9.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting arize-phoenix-otel>=0.6.1 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached arize_phoenix_otel-0.9.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting assemblyai==0.35.1 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached assemblyai-0.35.1-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting astra-assistants~=2.2.9 (from astra-assistants[tools]~=2.2.9->langflow->-r requirements.txt (line 1))\n",
      "  Using cached astra_assistants-2.2.11-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting atlassian-python-api==3.41.16 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached atlassian_python_api-3.41.16-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting beautifulsoup4==4.12.3 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting boto3==1.34.162 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached boto3-1.34.162-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting certifi<2025.0.0,>=2023.11.17 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting chromadb==0.5.23 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached chromadb-0.5.23-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting composio-core==0.7.1 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached composio_core-0.7.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting composio-langchain==0.7.1 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached composio_langchain-0.7.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting crewai==0.102.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached crewai-0.102.0-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting dspy-ai==2.5.41 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached dspy_ai-2.5.41-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting duckduckgo-search==7.2.1 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached duckduckgo_search-7.2.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting elasticsearch==8.16.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached elasticsearch-8.16.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting faiss-cpu==1.9.0.post1 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached faiss_cpu-1.9.0.post1-cp312-cp312-win_amd64.whl.metadata (4.5 kB)\n",
      "Collecting fake-useragent==1.5.1 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached fake_useragent-1.5.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting fastavro==1.9.7 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached fastavro-1.9.7-cp312-cp312-win_amd64.whl.metadata (5.6 kB)\n",
      "Collecting gitpython==3.1.43 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting google-api-python-client==2.154.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached google_api_python_client-2.154.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting google-search-results<3.0.0,>=2.4.1 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached google_search_results-2.4.2.tar.gz (18 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting huggingface-hub<1.0.0,>=0.23.2 (from huggingface-hub[inference]<1.0.0,>=0.23.2->langflow->-r requirements.txt (line 1))\n",
      "  Using cached huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting jq==1.8.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached jq-1.8.0-cp312-cp312-win_amd64.whl.metadata (7.2 kB)\n",
      "Collecting json-repair==0.30.3 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached json_repair-0.30.3-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting kubernetes==31.0.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting langchain-anthropic==0.3.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_anthropic-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langchain-astradb==0.5.2 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_astradb-0.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting langchain-aws==0.2.7 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_aws-0.2.7-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting langchain-chroma==0.1.4 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_chroma-0.1.4-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting langchain-cohere==0.3.3 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_cohere-0.3.3-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting langchain-community~=0.3.10 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_community-0.3.20-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting langchain-elasticsearch==0.3.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_elasticsearch-0.3.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting langchain-google-calendar-tools==0.0.1 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_google_calendar_tools-0.0.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting langchain-google-community==2.0.3 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_google_community-2.0.3-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting langchain-google-genai==2.0.6 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_google_genai-2.0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting langchain-google-vertexai==2.0.7 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_google_vertexai-2.0.7-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting langchain-groq==0.2.1 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_groq-0.2.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain-milvus==0.1.7 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_milvus-0.1.7-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langchain-mistralai==0.2.3 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_mistralai-0.2.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting langchain-mongodb==0.2.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_mongodb-0.2.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting langchain-nvidia-ai-endpoints==0.3.8 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_nvidia_ai_endpoints-0.3.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting langchain-ollama==0.2.1 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_ollama-0.2.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langchain-openai==0.2.12 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_openai-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting langchain-pinecone==0.2.2 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_pinecone-0.2.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting langchain-sambanova==0.1.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_sambanova-0.1.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting langchain-unstructured==0.1.5 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_unstructured-0.1.5-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting langchain==0.3.10 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain-0.3.10-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langflow-base==0.2.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langflow_base-0.2.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting langfuse==2.53.9 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langfuse-2.53.9-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting langsmith==0.1.147 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langwatch==0.1.16 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langwatch-0.1.16-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting lark==1.2.2 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting litellm==1.60.2 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached litellm-1.60.2-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting markdown==3.7 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: markupsafe==3.0.2 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from langflow->-r requirements.txt (line 1)) (3.0.2)\n",
      "Collecting mcp>=0.9.1 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached mcp-1.5.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting mem0ai==0.1.34 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached mem0ai-0.1.34-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting metal-sdk==2.5.1 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached metal_sdk-2.5.1-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting metaphor-python==0.1.23 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached metaphor_python-0.1.23-py3-none-any.whl.metadata (636 bytes)\n",
      "Collecting needle-python>=0.4.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached needle_python-0.4.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting networkx==3.4.2 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting nltk==3.9.1 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting numexpr==2.10.2 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached numexpr-2.10.2-cp312-cp312-win_amd64.whl.metadata (8.3 kB)\n",
      "Collecting openinference-instrumentation-langchain>=0.1.29 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached openinference_instrumentation_langchain-0.1.37-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting opensearch-py==2.8.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached opensearch_py-2.8.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting pgvector==0.3.6 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached pgvector-0.3.6-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pyarrow==19.0.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached pyarrow-19.0.0-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting pydantic-ai>=0.0.19 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached pydantic_ai-0.0.43-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pydantic-settings==2.4.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached pydantic_settings-2.4.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting pymongo==4.10.1 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached pymongo-4.10.1-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "Collecting pytube==15.0.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting pywin32==307 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached pywin32-307-cp312-cp312-win_amd64.whl.metadata (8.3 kB)\n",
      "Collecting qdrant-client==1.9.2 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached qdrant_client-1.9.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting qianfan==0.3.5 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached qianfan-0.3.5-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting ragstack-ai-knowledge-store==0.2.1 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached ragstack_ai_knowledge_store-0.2.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting redis==5.2.1 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached redis-5.2.1-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting scrapegraph-py>=1.12.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached scrapegraph_py-1.12.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting smolagents>=1.8.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached smolagents-1.12.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting spider-client==0.1.24 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached spider-client-0.1.24.tar.gz (15 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=2.0.38 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from sqlalchemy[aiosqlite,postgresql-psycopg2binary,postgresql-psycopgbinary]<3.0.0,>=2.0.38->langflow->-r requirements.txt (line 1)) (2.0.39)\n",
      "Collecting sseclient-py==1.8.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached sseclient_py-1.8.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting supabase==2.6.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached supabase-2.6.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting types-cachetools==5.5.0.20240820 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached types_cachetools-5.5.0.20240820-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting upstash-vector==0.6.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached upstash_vector-0.6.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting uv>=0.5.7 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached uv-0.6.9-py3-none-win_amd64.whl.metadata (11 kB)\n",
      "Collecting weaviate-client==4.10.2 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached weaviate_client-4.10.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting wikipedia==1.4.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting wolframalpha==5.1.3 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached wolframalpha-5.1.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting yfinance==0.2.50 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached yfinance-0.2.50-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting youtube-transcript-api==0.6.3 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached youtube_transcript_api-0.6.3-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting zep-python==2.0.2 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached zep_python-2.0.2-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: httpx>=0.19.0 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from assemblyai==0.35.1->langflow->-r requirements.txt (line 1)) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=1.10.17 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from assemblyai==0.35.1->langflow->-r requirements.txt (line 1)) (2.10.6)\n",
      "Requirement already satisfied: typing-extensions>=3.7 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from assemblyai==0.35.1->langflow->-r requirements.txt (line 1)) (4.12.2)\n",
      "Collecting websockets>=11.0 (from assemblyai==0.35.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached websockets-15.0.1-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
      "Collecting deprecated (from atlassian-python-api==3.41.16->langflow->-r requirements.txt (line 1))\n",
      "  Using cached Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from atlassian-python-api==3.41.16->langflow->-r requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: six in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from atlassian-python-api==3.41.16->langflow->-r requirements.txt (line 1)) (1.17.0)\n",
      "Collecting oauthlib (from atlassian-python-api==3.41.16->langflow->-r requirements.txt (line 1))\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting requests-oauthlib (from atlassian-python-api==3.41.16->langflow->-r requirements.txt (line 1))\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting jmespath (from atlassian-python-api==3.41.16->langflow->-r requirements.txt (line 1))\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from beautifulsoup4==4.12.3->langflow->-r requirements.txt (line 1)) (2.6)\n",
      "Collecting botocore<1.35.0,>=1.34.162 (from boto3==1.34.162->langflow->-r requirements.txt (line 1))\n",
      "  Using cached botocore-1.34.162-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3==1.34.162->langflow->-r requirements.txt (line 1))\n",
      "  Using cached s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting build>=1.0.3 (from chromadb==0.5.23->langflow->-r requirements.txt (line 1))\n",
      "  Using cached build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb==0.5.23->langflow->-r requirements.txt (line 1))\n",
      "  Using cached chroma_hnswlib-0.7.6.tar.gz (32 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting fastapi>=0.95.2 (from chromadb==0.5.23->langflow->-r requirements.txt (line 1))\n",
      "  Using cached fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb==0.5.23->langflow->-r requirements.txt (line 1))\n",
      "  Using cached uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting numpy>=1.22.5 (from chromadb==0.5.23->langflow->-r requirements.txt (line 1))\n",
      "  Using cached numpy-2.2.4-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting posthog>=2.4.0 (from chromadb==0.5.23->langflow->-r requirements.txt (line 1))\n",
      "  Using cached posthog-3.21.0-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb==0.5.23->langflow->-r requirements.txt (line 1))\n",
      "  Using cached onnxruntime-1.21.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb==0.5.23->langflow->-r requirements.txt (line 1))\n",
      "  Using cached opentelemetry_api-1.31.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb==0.5.23->langflow->-r requirements.txt (line 1))\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.31.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb==0.5.23->langflow->-r requirements.txt (line 1))\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.52b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb==0.5.23->langflow->-r requirements.txt (line 1))\n",
      "  Using cached opentelemetry_sdk-1.31.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting tokenizers<=0.20.3,>=0.13.2 (from chromadb==0.5.23->langflow->-r requirements.txt (line 1))\n",
      "  Using cached tokenizers-0.20.3-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb==0.5.23->langflow->-r requirements.txt (line 1))\n",
      "  Using cached PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting tqdm>=4.65.0 (from chromadb==0.5.23->langflow->-r requirements.txt (line 1))\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from chromadb==0.5.23->langflow->-r requirements.txt (line 1)) (7.7.0)\n",
      "Collecting importlib-resources (from chromadb==0.5.23->langflow->-r requirements.txt (line 1))\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb==0.5.23->langflow->-r requirements.txt (line 1))\n",
      "  Using cached grpcio-1.71.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb==0.5.23->langflow->-r requirements.txt (line 1))\n",
      "  Using cached bcrypt-4.3.0-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb==0.5.23->langflow->-r requirements.txt (line 1))\n",
      "  Using cached typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from chromadb==0.5.23->langflow->-r requirements.txt (line 1)) (9.0.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from chromadb==0.5.23->langflow->-r requirements.txt (line 1)) (6.0.2)\n",
      "Collecting mmh3>=4.0.1 (from chromadb==0.5.23->langflow->-r requirements.txt (line 1))\n",
      "  Using cached mmh3-5.1.0-cp312-cp312-win_amd64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from chromadb==0.5.23->langflow->-r requirements.txt (line 1)) (3.10.15)\n",
      "Collecting rich>=10.11.0 (from chromadb==0.5.23->langflow->-r requirements.txt (line 1))\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting aiohttp (from composio-core==0.7.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached aiohttp-3.11.14-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: jsonschema<5,>=4.21.1 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from composio-core==0.7.1->langflow->-r requirements.txt (line 1)) (4.23.0)\n",
      "Collecting sentry-sdk>=2.0.0 (from composio-core==0.7.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached sentry_sdk-2.24.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pysher==1.0.8 (from composio-core==0.7.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached Pysher-1.0.8.tar.gz (9.1 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting importlib-metadata>=4.8.1 (from composio-core==0.7.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting jsonref>=1.1.0 (from composio-core==0.7.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting inflection>=0.5.1 (from composio-core==0.7.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached inflection-0.5.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting semver>=2.13.0 (from composio-core==0.7.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting click (from composio-core==0.7.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyperclip<2,>=1.8.2 (from composio-core==0.7.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached pyperclip-1.9.0.tar.gz (20 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting paramiko>=3.4.1 (from composio-core==0.7.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached paramiko-3.5.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langchainhub>=0.1.15 (from composio-langchain==0.7.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchainhub-0.1.21-py3-none-any.whl.metadata (659 bytes)\n",
      "Collecting appdirs>=1.4.4 (from crewai==0.102.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting auth0-python>=4.7.1 (from crewai==0.102.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached auth0_python-4.8.1-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting blinker>=1.9.0 (from crewai==0.102.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting instructor>=1.3.3 (from crewai==0.102.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached instructor-1.7.7-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: json5>=0.10.0 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from crewai==0.102.0->langflow->-r requirements.txt (line 1)) (0.10.0)\n",
      "Collecting openai>=1.13.3 (from crewai==0.102.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached openai-1.68.2-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting openpyxl>=3.1.5 (from crewai==0.102.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http>=1.22.0 (from crewai==0.102.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached opentelemetry_exporter_otlp_proto_http-1.31.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting pdfplumber>=0.11.4 (from crewai==0.102.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting pyvis>=0.3.2 (from crewai==0.102.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting regex>=2024.9.11 (from crewai==0.102.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tomli-w>=1.1.0 (from crewai==0.102.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached tomli_w-1.2.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting tomli>=2.0.2 (from crewai==0.102.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached tomli-2.2.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting dspy>=2.5.3 (from dspy-ai==2.5.41->langflow->-r requirements.txt (line 1))\n",
      "  Using cached dspy-2.6.14-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting primp>=0.10.0 (from duckduckgo-search==7.2.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached primp-0.14.0-cp38-abi3-win_amd64.whl.metadata (13 kB)\n",
      "Collecting lxml>=5.3.0 (from duckduckgo-search==7.2.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached lxml-5.3.1-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting elastic-transport<9,>=8.15.1 (from elasticsearch==8.16.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached elastic_transport-8.17.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from faiss-cpu==1.9.0.post1->langflow->-r requirements.txt (line 1)) (24.2)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython==3.1.43->langflow->-r requirements.txt (line 1))\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client==2.154.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 (from google-api-python-client==2.154.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client==2.154.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 (from google-api-python-client==2.154.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached google_api_core-2.24.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client==2.154.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from kubernetes==31.0.0->langflow->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from kubernetes==31.0.0->langflow->-r requirements.txt (line 1)) (1.8.0)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from kubernetes==31.0.0->langflow->-r requirements.txt (line 1)) (2.3.0)\n",
      "Collecting durationpy>=0.7 (from kubernetes==31.0.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.22 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from langchain==0.3.10->langflow->-r requirements.txt (line 1)) (0.3.47)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from langchain==0.3.10->langflow->-r requirements.txt (line 1)) (0.3.7)\n",
      "Collecting anthropic<1,>=0.39.0 (from langchain-anthropic==0.3.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached anthropic-0.49.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from langchain-anthropic==0.3.0->langflow->-r requirements.txt (line 1)) (0.7.1)\n",
      "Collecting astrapy<2.0.0,>=1.5.2 (from langchain-astradb==0.5.2->langflow->-r requirements.txt (line 1))\n",
      "  Using cached astrapy-1.5.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.22.5 (from chromadb==0.5.23->langflow->-r requirements.txt (line 1))\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Collecting cohere<6.0,>=5.5.6 (from langchain-cohere==0.3.3->langflow->-r requirements.txt (line 1))\n",
      "  Using cached cohere-5.14.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting langchain-experimental<0.4.0,>=0.3.0 (from langchain-cohere==0.3.3->langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting pandas>=1.4.3 (from langchain-cohere==0.3.3->langflow->-r requirements.txt (line 1))\n",
      "  Using cached pandas-2.2.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting tabulate<0.10.0,>=0.9.0 (from langchain-cohere==0.3.3->langflow->-r requirements.txt (line 1))\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting google-auth-oauthlib>=1.1.0 (from langchain-google-calendar-tools==0.0.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached google_auth_oauthlib-1.2.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting protobuf>=4.25.0 (from langchain-google-calendar-tools==0.0.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached protobuf-6.30.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting pytz>=2023.3.post1 (from langchain-google-calendar-tools==0.0.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting google-cloud-core<3.0.0,>=2.4.1 (from langchain-google-community==2.0.3->langflow->-r requirements.txt (line 1))\n",
      "  Using cached google_cloud_core-2.4.3-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai==2.0.6->langflow->-r requirements.txt (line 1))\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting google-generativeai<0.9.0,>=0.8.0 (from langchain-google-genai==2.0.6->langflow->-r requirements.txt (line 1))\n",
      "  Using cached google_generativeai-0.8.4-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting google-cloud-aiplatform<2.0.0,>=1.70.0 (from langchain-google-vertexai==2.0.7->langflow->-r requirements.txt (line 1))\n",
      "  Using cached google_cloud_aiplatform-1.85.0-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting google-cloud-storage<3.0.0,>=2.18.0 (from langchain-google-vertexai==2.0.7->langflow->-r requirements.txt (line 1))\n",
      "  Using cached google_cloud_storage-2.19.0-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting httpx>=0.19.0 (from assemblyai==0.35.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-google-vertexai==2.0.7->langflow->-r requirements.txt (line 1))\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting groq<1,>=0.4.1 (from langchain-groq==0.2.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached groq-0.20.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pymilvus<3.0.0,>=2.4.3 (from langchain-milvus==0.1.7->langflow->-r requirements.txt (line 1))\n",
      "  Using cached pymilvus-2.5.6-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting ollama<1,>=0.3.0 (from langchain-ollama==0.2.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached ollama-0.4.7-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai==0.2.12->langflow->-r requirements.txt (line 1))\n",
      "  Using cached tiktoken-0.9.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting aiohttp (from composio-core==0.7.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached aiohttp-3.10.11-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting langchain-tests<0.4.0,>=0.3.7 (from langchain-pinecone==0.2.2->langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_tests-0.3.15-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting pinecone<6.0.0,>=5.4.0 (from langchain-pinecone==0.2.2->langflow->-r requirements.txt (line 1))\n",
      "  Using cached pinecone-5.4.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting types-requests (from langchain-sambanova==0.1.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached types_requests-2.32.0.20250306-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting unstructured-client<0.26.0,>=0.25.0 (from langchain-unstructured==0.1.5->langflow->-r requirements.txt (line 1))\n",
      "  Using cached unstructured_client-0.25.9-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting aiofiles<25.0.0,>=24.1.0 (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting aiosqlite>=0.20.0 (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting alembic<2.0.0,>=1.13.0 (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting asyncer<1.0.0,>=0.0.5 (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached asyncer-0.0.8-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb==0.5.23->langflow->-r requirements.txt (line 1))\n",
      "  Using cached bcrypt-4.0.1-cp36-abi3-win_amd64.whl.metadata (9.0 kB)\n",
      "Collecting cachetools<6.0.0,>=5.5.0 (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting chardet<6.0.0,>=5.2.0 (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting clickhouse-connect==0.7.19 (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached clickhouse_connect-0.7.19-cp312-cp312-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting cryptography<44.0.0,>=42.0.5 (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached cryptography-43.0.3-cp39-abi3-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting diskcache<6.0.0,>=5.6.3 (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting docstring-parser<1.0.0,>=0.16 (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting duckdb<2.0.0,>=1.0.0 (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached duckdb-1.2.1-cp312-cp312-win_amd64.whl.metadata (995 bytes)\n",
      "Collecting emoji<3.0.0,>=2.12.0 (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting fastapi-pagination<1.0.0,>=0.12.29 (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached fastapi_pagination-0.12.34-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting filelock<4.0.0,>=3.15.4 (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting firecrawl-py<2.0.0,>=1.0.16 (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached firecrawl_py-1.14.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting grandalf<1.0.0,>=0.8.0 (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached grandalf-0.8-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: greenlet>=3.1.1 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1)) (3.1.1)\n",
      "Collecting gunicorn<24.0.0,>=22.0.0 (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting loguru<1.0.0,>=0.7.1 (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting multiprocess<1.0.0,>=0.70.14 (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached multiprocess-0.70.17-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting nanoid<3.0.0,>=2.0.0 (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached nanoid-2.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.6.0 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1)) (1.6.0)\n",
      "Collecting opentelemetry-exporter-prometheus<1.0.0,>=0.46b0 (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached opentelemetry_exporter_prometheus-0.52b1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting passlib<2.0.0,>=1.7.4 (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached passlib-1.7.4-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting pillow<12.0.0,>=11.1.0 (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached pillow-11.1.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=4.2.0 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1)) (4.3.7)\n",
      "Requirement already satisfied: prometheus-client<1.0.0,>=0.20.0 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1)) (0.21.1)\n",
      "Collecting pypdf~=5.1.0 (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting python-docx<2.0.0,>=1.1.0 (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting python-jose<4.0.0,>=3.3.0 (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached python_jose-3.4.0-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting python-multipart<1.0.0,>=0.0.12 (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting setuptools<76.0.0,>=70 (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached setuptools-75.9.1-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting sqlmodel==0.0.22 (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached sqlmodel-0.0.22-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting uncurl<1.0.0,>=0.0.11 (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached uncurl-0.0.11-py3-none-any.whl.metadata (300 bytes)\n",
      "Collecting validators>=0.34.0 (from langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached validators-0.34.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.4.0 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from langfuse==2.53.9->langflow->-r requirements.txt (line 1)) (4.9.0)\n",
      "Collecting backoff>=1.10.0 (from langfuse==2.53.9->langflow->-r requirements.txt (line 1))\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: idna<4.0,>=3.7 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from langfuse==2.53.9->langflow->-r requirements.txt (line 1)) (3.10)\n",
      "Collecting wrapt<2.0,>=1.14 (from langfuse==2.53.9->langflow->-r requirements.txt (line 1))\n",
      "  Using cached wrapt-1.17.2-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from langsmith==0.1.147->langflow->-r requirements.txt (line 1)) (1.0.0)\n",
      "Collecting coolname<3.0.0,>=2.2.0 (from langwatch==0.1.16->langflow->-r requirements.txt (line 1))\n",
      "  Using cached coolname-2.2.0-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting retry<0.10.0,>=0.9.2 (from langwatch==0.1.16->langflow->-r requirements.txt (line 1))\n",
      "  Using cached retry-0.9.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from litellm==1.60.2->langflow->-r requirements.txt (line 1)) (3.1.6)\n",
      "Collecting pytz>=2023.3.post1 (from langchain-google-calendar-tools==0.0.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting joblib (from nltk==3.9.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting Events (from opensearch-py==2.8.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached Events-0.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo==4.10.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting grpcio-tools>=1.41.0 (from qdrant-client==1.9.2->langflow->-r requirements.txt (line 1))\n",
      "  Using cached grpcio_tools-1.71.0-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client==1.9.2->langflow->-r requirements.txt (line 1))\n",
      "  Using cached portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting aiolimiter>=1.1.0 (from qianfan==0.3.5->langflow->-r requirements.txt (line 1))\n",
      "  Using cached aiolimiter-1.2.1-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting bce-python-sdk>=0.8.79 (from qianfan==0.3.5->langflow->-r requirements.txt (line 1))\n",
      "  Using cached bce_python_sdk-0.9.29-py3-none-any.whl.metadata (416 bytes)\n",
      "Collecting clevercsv (from qianfan==0.3.5->langflow->-r requirements.txt (line 1))\n",
      "  Using cached clevercsv-0.8.3-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting ijson (from qianfan==0.3.5->langflow->-r requirements.txt (line 1))\n",
      "  Using cached ijson-3.3.0-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.38 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from qianfan==0.3.5->langflow->-r requirements.txt (line 1)) (3.0.50)\n",
      "Collecting tenacity>=8.2.3 (from chromadb==0.5.23->langflow->-r requirements.txt (line 1))\n",
      "  Using cached tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting cassio<0.2.0,>=0.1.7 (from ragstack-ai-knowledge-store==0.2.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached cassio-0.1.10-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting gotrue<3.0,>=1.3 (from supabase==2.6.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached gotrue-2.11.4-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting postgrest<0.17.0,>=0.14 (from supabase==2.6.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached postgrest-0.16.11-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting realtime<2.0.0,>=1.0.0 (from supabase==2.6.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached realtime-1.0.6-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting storage3<0.8.0,>=0.5.3 (from supabase==2.6.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached storage3-0.7.7-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting supafunc<0.6.0,>=0.3.1 (from supabase==2.6.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached supafunc-0.5.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting authlib<1.3.2,>=1.2.1 (from weaviate-client==4.10.2->langflow->-r requirements.txt (line 1))\n",
      "  Using cached Authlib-1.3.1-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting grpcio-health-checking<2.0.0,>=1.66.2 (from weaviate-client==4.10.2->langflow->-r requirements.txt (line 1))\n",
      "  Using cached grpcio_health_checking-1.71.0-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting xmltodict (from wolframalpha==5.1.3->langflow->-r requirements.txt (line 1))\n",
      "  Using cached xmltodict-0.14.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting more-itertools (from wolframalpha==5.1.3->langflow->-r requirements.txt (line 1))\n",
      "  Using cached more_itertools-10.6.0-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting jaraco.context (from wolframalpha==5.1.3->langflow->-r requirements.txt (line 1))\n",
      "  Using cached jaraco.context-6.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting multidict (from wolframalpha==5.1.3->langflow->-r requirements.txt (line 1))\n",
      "  Using cached multidict-6.2.0-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting multitasking>=0.0.7 (from yfinance==0.2.50->langflow->-r requirements.txt (line 1))\n",
      "  Using cached multitasking-0.0.11-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting frozendict>=2.3.4 (from yfinance==0.2.50->langflow->-r requirements.txt (line 1))\n",
      "  Using cached frozendict-2.4.6-py312-none-any.whl.metadata (23 kB)\n",
      "Collecting peewee>=3.16.2 (from yfinance==0.2.50->langflow->-r requirements.txt (line 1))\n",
      "  Using cached peewee-3.17.9.tar.gz (3.0 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting html5lib>=1.1 (from yfinance==0.2.50->langflow->-r requirements.txt (line 1))\n",
      "  Using cached html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: zstandard in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from clickhouse-connect==0.7.19->langflow-base==0.2.0->langflow->-r requirements.txt (line 1)) (0.23.0)\n",
      "Collecting lz4 (from clickhouse-connect==0.7.19->langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached lz4-4.4.3-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.4.3->langchain-cohere==0.3.3->langflow->-r requirements.txt (line 1))\n",
      "  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: notebook in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from jupyter->-r requirements.txt (line 3)) (7.3.3)\n",
      "Requirement already satisfied: jupyter-console in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from jupyter->-r requirements.txt (line 3)) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from jupyter->-r requirements.txt (line 3)) (7.16.6)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from jupyter->-r requirements.txt (line 3)) (6.29.5)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from jupyter->-r requirements.txt (line 3)) (8.1.5)\n",
      "Requirement already satisfied: jupyterlab in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from jupyter->-r requirements.txt (line 3)) (4.3.6)\n",
      "Collecting pyautogen==0.8.3 (from ag2>=0.1.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached pyautogen-0.8.3-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting docker (from pyautogen==0.8.3->ag2>=0.1.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "INFO: pip is looking at multiple versions of pyautogen to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting ag2>=0.1.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached ag2-0.8.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from httpx>=0.19.0->assemblyai==0.35.1->langflow->-r requirements.txt (line 1)) (1.0.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from httpx>=0.19.0->assemblyai==0.35.1->langflow->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.19.0->assemblyai==0.35.1->langflow->-r requirements.txt (line 1)) (0.14.0)\n",
      "Collecting pyautogen==0.8.2 (from ag2>=0.1.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached pyautogen-0.8.2-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting ag2>=0.1.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached ag2-0.8.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting pyautogen==0.8.1 (from ag2>=0.1.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached pyautogen-0.8.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting fast-depends<3,>=2.4.12 (from pyautogen==0.8.1->ag2>=0.1.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached fast_depends-2.4.12-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting ag2>=0.1.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached ag2-0.8.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting pyautogen==0.8.0 (from ag2>=0.1.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached pyautogen-0.8.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting ag2>=0.1.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached ag2-0.7.6-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting pyautogen==0.7.6 (from ag2>=0.1.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached pyautogen-0.7.6-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting ag2>=0.1.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached ag2-0.7.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting pyautogen==0.7.5 (from ag2>=0.1.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached pyautogen-0.7.5-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting termcolor (from pyautogen==0.7.5->ag2>=0.1.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting websockets>=11.0 (from assemblyai==0.35.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached websockets-14.2-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
      "Collecting caio<0.10.0,>=0.9.0 (from aiofile<4.0.0,>=3.9.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached caio-0.9.21.tar.gz (26 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting apify-shared>=1.1.2 (from apify-client>=1.8.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached apify_shared-1.3.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting openinference-instrumentation>=0.1.21 (from arize-phoenix-otel>=0.6.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached openinference_instrumentation-0.1.24-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting openinference-semantic-conventions>=0.1.9 (from arize-phoenix-otel>=0.6.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached openinference_semantic_conventions-0.1.15-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting opentelemetry-exporter-otlp (from arize-phoenix-otel>=0.6.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached opentelemetry_exporter_otlp-1.31.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-proto>=1.12.0 (from arize-phoenix-otel>=0.6.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached opentelemetry_proto-1.31.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-semantic-conventions (from arize-phoenix-otel>=0.6.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached opentelemetry_semantic_conventions-0.52b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting lsprotocol<2024.0.0,>=2023.0.1 (from astra-assistants~=2.2.9->astra-assistants[tools]~=2.2.9->langflow->-r requirements.txt (line 1))\n",
      "  Using cached lsprotocol-2023.0.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting python-lsp-jsonrpc<2.0.0,>=1.1.2 (from astra-assistants~=2.2.9->astra-assistants[tools]~=2.2.9->langflow->-r requirements.txt (line 1))\n",
      "  Using cached python_lsp_jsonrpc-1.1.2-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting ruff<9.0.0,>=0.6.2 (from astra-assistants~=2.2.9->astra-assistants[tools]~=2.2.9->langflow->-r requirements.txt (line 1))\n",
      "  Using cached ruff-0.11.2-py3-none-win_amd64.whl.metadata (26 kB)\n",
      "Collecting tree-sitter<0.24.0,>=0.23.0 (from astra-assistants~=2.2.9->astra-assistants[tools]~=2.2.9->langflow->-r requirements.txt (line 1))\n",
      "  Using cached tree_sitter-0.23.2-cp312-cp312-win_amd64.whl.metadata (10 kB)\n",
      "Collecting tree-sitter-python<0.24.0,>=0.23.0 (from astra-assistants~=2.2.9->astra-assistants[tools]~=2.2.9->langflow->-r requirements.txt (line 1))\n",
      "  Using cached tree_sitter_python-0.23.6-cp39-abi3-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting e2b<2.0.0,>=1.0.1 (from astra-assistants[tools]~=2.2.9->langflow->-r requirements.txt (line 1))\n",
      "  Using cached e2b-1.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting e2b-code-interpreter<2.0.0,>=1.0.1 (from astra-assistants[tools]~=2.2.9->langflow->-r requirements.txt (line 1))\n",
      "  Using cached e2b_code_interpreter-1.1.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0.0,>=0.23.2->huggingface-hub[inference]<1.0.0,>=0.23.2->langflow->-r requirements.txt (line 1))\n",
      "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-community~=0.3.10 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_community-0.3.19-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Using cached langchain_community-0.3.18-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Using cached langchain_community-0.3.17-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Using cached langchain_community-0.3.16-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community~=0.3.10->langflow->-r requirements.txt (line 1))\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain-community~=0.3.10 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_community-0.3.15-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.14-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.13-py3-none-any.whl.metadata (2.9 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached langchain_community-0.3.12-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.11-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "INFO: pip is looking at multiple versions of mcp to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting mcp>=0.9.1 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached mcp-1.4.1-py3-none-any.whl.metadata (18 kB)\n",
      "  Using cached mcp-1.4.0-py3-none-any.whl.metadata (18 kB)\n",
      "  Using cached mcp-1.3.0-py3-none-any.whl.metadata (18 kB)\n",
      "  Using cached mcp-1.2.1-py3-none-any.whl.metadata (15 kB)\n",
      "  Using cached mcp-1.2.0-py3-none-any.whl.metadata (15 kB)\n",
      "  Using cached mcp-1.1.3-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting sse-starlette>=1.6.1 (from mcp>=0.9.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached sse_starlette-2.2.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting starlette>=0.27 (from mcp>=0.9.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting opentelemetry-instrumentation (from openinference-instrumentation-langchain>=0.1.29->langflow->-r requirements.txt (line 1))\n",
      "  Using cached opentelemetry_instrumentation-0.52b1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting pydantic-ai-slim==0.0.43 (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai>=0.0.19->langflow->-r requirements.txt (line 1))\n",
      "  Using cached pydantic_ai_slim-0.0.43-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting eval-type-backport>=0.2.0 (from pydantic-ai-slim==0.0.43->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai>=0.0.19->langflow->-r requirements.txt (line 1))\n",
      "  Using cached eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting griffe>=1.3.2 (from pydantic-ai-slim==0.0.43->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai>=0.0.19->langflow->-r requirements.txt (line 1))\n",
      "  Using cached griffe-1.6.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting pydantic-graph==0.0.43 (from pydantic-ai-slim==0.0.43->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai>=0.0.19->langflow->-r requirements.txt (line 1))\n",
      "  Using cached pydantic_graph-0.0.43-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic-ai-slim==0.0.43->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai>=0.0.19->langflow->-r requirements.txt (line 1))\n",
      "  Using cached typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting argcomplete>=3.5.0 (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai>=0.0.19->langflow->-r requirements.txt (line 1))\n",
      "  Using cached argcomplete-3.6.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting mistralai>=1.2.5 (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai>=0.0.19->langflow->-r requirements.txt (line 1))\n",
      "  Using cached mistralai-1.6.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting logfire-api>=1.2.0 (from pydantic-graph==0.0.43->pydantic-ai-slim==0.0.43->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai>=0.0.19->langflow->-r requirements.txt (line 1))\n",
      "  Using cached logfire_api-3.9.0-py3-none-any.whl.metadata (971 bytes)\n",
      "INFO: pip is still looking at multiple versions of mcp to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting langflow (from -r requirements.txt (line 1))\n",
      "  Using cached langflow-1.1.4.post1-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting composio-core==0.6.16 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached composio_core-0.6.16-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting composio-langchain==0.6.16 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached composio_langchain-0.6.16-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting crewai~=0.86.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached crewai-0.86.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting langchain-nvidia-ai-endpoints==0.3.5 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_nvidia_ai_endpoints-0.3.5-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting langflow-base==0.1.4.post1 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langflow_base-0.1.4.post1-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting litellm==1.59.8 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached litellm-1.59.8-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting pyarrow==17.0.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached pyarrow-17.0.0-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting pywin32<307,>=306 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached pywin32-306-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting orjson==3.10.0 (from langflow-base==0.1.4.post1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached orjson-3.10.0-cp312-none-win_amd64.whl.metadata (50 kB)\n",
      "Collecting pandas==2.2.2 (from langflow-base==0.1.4.post1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached pandas-2.2.2-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting pillow<11.0.0,>=10.2.0 (from langflow-base==0.1.4.post1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached pillow-10.4.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "INFO: pip is still looking at multiple versions of pyautogen to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting crewai-tools>=0.17.0 (from crewai~=0.86.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached crewai_tools-0.38.1-py3-none-any.whl.metadata (5.5 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting langflow (from -r requirements.txt (line 1))\n",
      "  Using cached langflow-1.1.4-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting langflow-base==0.1.4 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langflow_base-0.1.4-py3-none-any.whl.metadata (5.5 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting langflow (from -r requirements.txt (line 1))\n",
      "  Using cached langflow-1.1.3-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting langflow-base==0.1.3 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langflow_base-0.1.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting langflow (from -r requirements.txt (line 1))\n",
      "  Using cached langflow-1.1.2-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting composio-core==0.6.13 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached composio_core-0.6.13-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting composio-langchain==0.6.13 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached composio_langchain-0.6.13-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting langflow-base==0.1.2 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langflow_base-0.1.2-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting litellm==1.54.1 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached litellm-1.54.1-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting langflow (from -r requirements.txt (line 1))\n",
      "  Using cached langflow-1.1.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting assemblyai<1.0.0,>=0.33.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached assemblyai-0.37.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting atlassian-python-api<4.0.0,>=3.41.16 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached atlassian_python_api-3.41.21-py3-none-any.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.2 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from langflow->-r requirements.txt (line 1)) (4.13.3)\n",
      "Collecting chromadb<1.0.0,>=0.4 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting composio-langchain==0.5.42 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached composio_langchain-0.5.42-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting dspy-ai<3.0.0,>=2.4.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached dspy_ai-2.6.14-py3-none-any.whl.metadata (286 bytes)\n",
      "Collecting duckduckgo-search<7.0.0,>=6.3.4 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached duckduckgo_search-6.4.2-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting elasticsearch<9.0.0,>=8.12.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached elasticsearch-8.17.2-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting faiss-cpu<2.0.0,>=1.8.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached faiss_cpu-1.10.0-cp312-cp312-win_amd64.whl.metadata (4.5 kB)\n",
      "Collecting fastavro<2.0.0,>=1.8.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached fastavro-1.10.0-cp312-cp312-win_amd64.whl.metadata (5.7 kB)\n",
      "Collecting gitpython<4.0.0,>=3.1.43 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting google-api-python-client<3.0.0,>=2.130.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached google_api_python_client-2.165.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting json-repair<1.0.0,>=0.25.2 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached json_repair-0.40.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting langchain-anthropic<1.0.0,>=0.1.23 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_anthropic-0.3.10-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langchain-astradb~=0.5.2 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_astradb-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting langchain-aws<1.0.0,>=0.1.16 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_aws-0.2.17-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting langchain-chroma<1.0.0,>=0.1.1 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_chroma-0.2.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting langchain-cohere<1.0.0,>=0.1.5 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_cohere-0.4.3-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting langchain-elasticsearch<1.0.0,>=0.2.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_elasticsearch-0.3.2-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting langchain-google-community~=2.0.1 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_google_community-2.0.7-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting langchain-google-genai<3.0.0,>=2.0.1 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_google_genai-2.1.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting langchain-google-vertexai~=2.0.5 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_google_vertexai-2.0.16-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting langchain-groq<1.0.0,>=0.1.9 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_groq-0.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting langchain-milvus<1.0.0,>=0.1.1 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_milvus-0.1.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langchain-mistralai~=0.2.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_mistralai-0.2.9-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting langchain-mongodb<1.0.0,>=0.1.6 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_mongodb-0.5.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting langchain-nvidia-ai-endpoints~=0.3.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_nvidia_ai_endpoints-0.3.9-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting langchain-ollama<1.0.0,>=0.2.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_ollama-0.3.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting langchain-openai~=0.2.2 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_openai-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting langchain-pinecone<1.0.0,>=0.1.3 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_pinecone-0.2.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting langchain-unstructured~=0.1.5 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_unstructured-0.1.6-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting langchain~=0.3.3 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain-0.3.21-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langflow-base==0.1.1 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langflow_base-0.1.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting litellm<2.0.0,>=1.44.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached litellm-1.63.14-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting mem0ai<1.0.0,>=0.1.26 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached mem0ai-0.1.74-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting pgvector<1.0.0,>=0.2.3 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached pgvector-0.4.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting pymongo<5.0.0,>=4.6.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached pymongo-4.11.3-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "Collecting spider-client<1.0.0,>=0.0.27 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached spider-client-0.1.28.tar.gz (15 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting upstash-vector<1.0.0,>=0.5.0 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached upstash_vector-0.8.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting weaviate-client<5.0.0,>=4.8 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached weaviate_client-4.11.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting yfinance<1.0.0,>=0.2.40 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached yfinance-0.2.55-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting composio-core<=0.5.42,>=0.5.40 (from composio-langchain==0.5.42->langflow->-r requirements.txt (line 1))\n",
      "  Using cached composio_core-0.5.42-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting crewai~=0.80.0 (from langflow-base==0.1.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached crewai-0.80.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting pydantic>=2.6.4 (from composio-langchain==0.5.42->langflow->-r requirements.txt (line 1))\n",
      "  Using cached pydantic-2.7.4-py3-none-any.whl.metadata (109 kB)\n",
      "Collecting sqlmodel==0.0.18 (from langflow-base==0.1.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached sqlmodel-0.0.18-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb<1.0.0,>=0.4->langflow->-r requirements.txt (line 1))\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from cohere<6.0,>=5.5.6->langchain-cohere==0.3.3->langflow->-r requirements.txt (line 1)) (2.27.2)\n",
      "INFO: pip is looking at multiple versions of langchain-aws to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-aws<1.0.0,>=0.1.16 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_aws-0.2.16-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Using cached langchain_aws-0.2.15-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Using cached langchain_aws-0.2.14-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Using cached langchain_aws-0.2.13-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Using cached langchain_aws-0.2.12-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Using cached langchain_aws-0.2.11-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Using cached langchain_aws-0.2.10-py3-none-any.whl.metadata (3.2 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-aws to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached langchain_aws-0.2.9-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting types-pyyaml<7.0.0.0,>=6.0.12.20240917 (from langchain-cohere<1.0.0,>=0.1.5->langflow->-r requirements.txt (line 1))\n",
      "  Using cached types_PyYAML-6.0.12.20241230-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting google-ai-generativelanguage<0.7.0,>=0.6.16 (from langchain-google-genai<3.0.0,>=2.0.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached google_ai_generativelanguage-0.6.17-py3-none-any.whl.metadata (9.8 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-google-vertexai to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-google-vertexai~=2.0.5 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_google_vertexai-2.0.15-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached langchain_google_vertexai-2.0.14-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached langchain_google_vertexai-2.0.13-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached langchain_google_vertexai-2.0.12-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached langchain_google_vertexai-2.0.11-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached langchain_google_vertexai-2.0.10-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached langchain_google_vertexai-2.0.9-py3-none-any.whl.metadata (3.8 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-google-vertexai to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached langchain_google_vertexai-2.0.8-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb<1.0.0,>=0.4->langflow->-r requirements.txt (line 1))\n",
      "  Using cached onnxruntime-1.19.2-cp312-cp312-win_amd64.whl.metadata (4.7 kB)\n",
      "Collecting unstructured-client<1,>=0.27.0 (from langchain-unstructured~=0.1.5->langflow->-r requirements.txt (line 1))\n",
      "  Using cached unstructured_client-0.31.3-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting azure-search-documents<12.0.0,>=11.5.0 (from mem0ai<1.0.0,>=0.1.26->langflow->-r requirements.txt (line 1))\n",
      "  Using cached azure_search_documents-11.5.2-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting psycopg2-binary<3.0.0,>=2.9.10 (from mem0ai<1.0.0,>=0.1.26->langflow->-r requirements.txt (line 1))\n",
      "  Using cached psycopg2_binary-2.9.10-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting psycopg>=3.0.7 (from psycopg[binary]>=3.0.7; extra == \"postgresql-psycopgbinary\"->sqlalchemy[aiosqlite,postgresql-psycopg2binary,postgresql-psycopgbinary]<3.0.0,>=2.0.38->langflow->-r requirements.txt (line 1))\n",
      "  Using cached psycopg-3.2.6-py3-none-any.whl.metadata (4.4 kB)\n",
      "INFO: pip is looking at multiple versions of weaviate-client to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting weaviate-client<5.0.0,>=4.8 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached weaviate_client-4.11.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached weaviate_client-4.11.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached weaviate_client-4.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached weaviate_client-4.10.3-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached weaviate_client-4.10.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached weaviate_client-4.10.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting httpx<1.0.0,>=0.27 (from httpx[http2]<1.0.0,>=0.27->langflow-base==0.1.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "INFO: pip is still looking at multiple versions of weaviate-client to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting weaviate-client<5.0.0,>=4.8 (from langflow->-r requirements.txt (line 1))\n",
      "  Using cached weaviate_client-4.9.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from ipykernel->jupyter->-r requirements.txt (line 3)) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from ipykernel->jupyter->-r requirements.txt (line 3)) (1.8.13)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from ipykernel->jupyter->-r requirements.txt (line 3)) (9.0.2)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from ipykernel->jupyter->-r requirements.txt (line 3)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from ipykernel->jupyter->-r requirements.txt (line 3)) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from ipykernel->jupyter->-r requirements.txt (line 3)) (0.1.7)\n",
      "Requirement already satisfied: psutil in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from ipykernel->jupyter->-r requirements.txt (line 3)) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from ipykernel->jupyter->-r requirements.txt (line 3)) (26.3.0)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from ipykernel->jupyter->-r requirements.txt (line 3)) (6.4.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from ipykernel->jupyter->-r requirements.txt (line 3)) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from ipywidgets->jupyter->-r requirements.txt (line 3)) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from ipywidgets->jupyter->-r requirements.txt (line 3)) (3.0.13)\n",
      "Requirement already satisfied: pygments in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from jupyter-console->jupyter->-r requirements.txt (line 3)) (2.19.1)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from jupyterlab->jupyter->-r requirements.txt (line 3)) (2.0.5)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from jupyterlab->jupyter->-r requirements.txt (line 3)) (2.2.5)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from jupyterlab->jupyter->-r requirements.txt (line 3)) (2.15.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from jupyterlab->jupyter->-r requirements.txt (line 3)) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from jupyterlab->jupyter->-r requirements.txt (line 3)) (0.2.4)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->-r requirements.txt (line 3)) (6.2.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 3)) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 3)) (3.1.3)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 3)) (0.10.2)\n",
      "Requirement already satisfied: nbformat>=5.7 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 3)) (5.10.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 3)) (1.5.1)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->composio-core==0.7.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->composio-core==0.7.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from aiohttp->composio-core==0.7.1->langflow->-r requirements.txt (line 1)) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->composio-core==0.7.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached frozenlist-1.5.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp->composio-core==0.7.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached yarl-1.18.3-cp312-cp312-win_amd64.whl.metadata (71 kB)\n",
      "Collecting Mako (from alembic<2.0.0,>=1.13.0->langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting distro<2,>=1.7.0 (from anthropic<1,>=0.39.0->langchain-anthropic==0.3.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from anthropic<1,>=0.39.0->langchain-anthropic==0.3.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached jiter-0.9.0-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting deprecation<2.2.0,>=2.1.0 (from astrapy<2.0.0,>=1.5.2->langchain-astradb==0.5.2->langflow->-r requirements.txt (line 1))\n",
      "  Using cached deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting toml<0.11.0,>=0.10.2 (from astrapy<2.0.0,>=1.5.2->langchain-astradb==0.5.2->langflow->-r requirements.txt (line 1))\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting uuid6>=2024.1.12 (from astrapy<2.0.0,>=1.5.2->langchain-astradb==0.5.2->langflow->-r requirements.txt (line 1))\n",
      "  Using cached uuid6-2024.7.10-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting azure-core>=1.28.0 (from azure-search-documents<12.0.0,>=11.5.0->mem0ai<1.0.0,>=0.1.26->langflow->-r requirements.txt (line 1))\n",
      "  Using cached azure_core-1.32.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting azure-common>=1.1 (from azure-search-documents<12.0.0,>=11.5.0->mem0ai<1.0.0,>=0.1.26->langflow->-r requirements.txt (line 1))\n",
      "  Using cached azure_common-1.1.28-py2.py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting isodate>=0.6.0 (from azure-search-documents<12.0.0,>=11.5.0->mem0ai<1.0.0,>=0.1.26->langflow->-r requirements.txt (line 1))\n",
      "  Using cached isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pycryptodome>=3.8.0 (from bce-python-sdk>=0.8.79->qianfan==0.3.5->langflow->-r requirements.txt (line 1))\n",
      "  Using cached pycryptodome-3.22.0-cp37-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting future>=0.6.0 (from bce-python-sdk>=0.8.79->qianfan==0.3.5->langflow->-r requirements.txt (line 1))\n",
      "  Using cached future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: webencodings in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter->-r requirements.txt (line 3)) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->-r requirements.txt (line 3)) (1.4.0)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb==0.5.23->langflow->-r requirements.txt (line 1))\n",
      "  Using cached pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb==0.5.23->langflow->-r requirements.txt (line 1)) (0.4.6)\n",
      "Collecting cassandra-driver<4.0.0,>=3.28.0 (from cassio<0.2.0,>=0.1.7->ragstack-ai-knowledge-store==0.2.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached cassandra_driver-3.29.2-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from cryptography<44.0.0,>=42.0.5->langflow-base==0.2.0->langflow->-r requirements.txt (line 1)) (1.17.1)\n",
      "INFO: pip is looking at multiple versions of dspy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting dspy>=2.6.5 (from dspy-ai<3.0.0,>=2.4.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached dspy-2.6.13-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting ujson (from dspy>=2.6.5->dspy-ai<3.0.0,>=2.4.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached ujson-5.10.0-cp312-cp312-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting datasets>=2.14.6 (from dspy>=2.6.5->dspy-ai<3.0.0,>=2.4.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached datasets-3.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting optuna (from dspy>=2.6.5->dspy-ai<3.0.0,>=2.4.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting magicattr~=0.1.6 (from dspy>=2.6.5->dspy-ai<3.0.0,>=2.4.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached magicattr-0.1.6-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting cloudpickle (from dspy>=2.6.5->dspy-ai<3.0.0,>=2.4.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting protobuf>=4.25.0 (from langchain-google-calendar-tools==0.0.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached protobuf-5.29.4-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting simsimd>=3 (from elasticsearch[vectorstore-mmr]<9.0.0,>=8.13.1->langchain-elasticsearch<1.0.0,>=0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached simsimd-6.2.1-cp312-cp312-win_amd64.whl.metadata (67 kB)\n",
      "INFO: pip is looking at multiple versions of firecrawl-py to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting firecrawl-py<2.0.0,>=1.0.16 (from langflow-base==0.1.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached firecrawl_py-1.14.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached firecrawl_py-1.13.5-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached firecrawl_py-1.13.4-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached firecrawl_py-1.13.3-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached firecrawl_py-1.13.2-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached firecrawl_py-1.13.1-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached firecrawl_py-1.13.0-py3-none-any.whl.metadata (10 kB)\n",
      "INFO: pip is still looking at multiple versions of firecrawl-py to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached firecrawl_py-1.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached firecrawl_py-1.11.1-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached firecrawl_py-1.11.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached firecrawl_py-1.10.2-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached firecrawl_py-1.10.1-py3-none-any.whl.metadata (10 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached firecrawl_py-1.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached firecrawl_py-1.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached firecrawl_py-1.8.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached firecrawl_py-1.7.1-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached firecrawl_py-1.7.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached firecrawl_py-1.6.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython==3.1.43->langflow->-r requirements.txt (line 1))\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai<3.0.0,>=2.0.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client==2.154.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached googleapis_common_protos-1.69.2-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client==2.154.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client==2.154.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 (from google-cloud-aiplatform<2.0.0,>=1.70.0->langchain-google-vertexai==2.0.7->langflow->-r requirements.txt (line 1))\n",
      "  Using cached google_cloud_bigquery-3.30.0-py2.py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting google-cloud-resource-manager<3.0.0,>=1.3.3 (from google-cloud-aiplatform<2.0.0,>=1.70.0->langchain-google-vertexai==2.0.7->langflow->-r requirements.txt (line 1))\n",
      "  Using cached google_cloud_resource_manager-1.14.2-py3-none-any.whl.metadata (9.6 kB)\n",
      "Collecting shapely<3.0.0 (from google-cloud-aiplatform<2.0.0,>=1.70.0->langchain-google-vertexai==2.0.7->langflow->-r requirements.txt (line 1))\n",
      "  Using cached shapely-2.0.7-cp312-cp312-win_amd64.whl.metadata (7.1 kB)\n",
      "Collecting google-resumable-media>=2.7.2 (from google-cloud-storage<3.0.0,>=2.18.0->langchain-google-vertexai==2.0.7->langflow->-r requirements.txt (line 1))\n",
      "  Using cached google_resumable_media-2.7.2-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage<3.0.0,>=2.18.0->langchain-google-vertexai==2.0.7->langflow->-r requirements.txt (line 1))\n",
      "  Using cached google_crc32c-1.7.0-cp312-cp312-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting pyparsing (from grandalf<1.0.0,>=0.8.0->langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting h2<5,>=3 (from httpx[http2]<1.0.0,>=0.27->langflow-base==0.1.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached h2-4.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata>=4.8.1->composio-core==0.7.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: decorator in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 3)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 3)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 3)) (0.19.2)\n",
      "Requirement already satisfied: stack_data in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 3)) (0.6.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from jsonschema<5,>=4.21.1->composio-core==0.7.1->langflow->-r requirements.txt (line 1)) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from jsonschema<5,>=4.21.1->composio-core==0.7.1->langflow->-r requirements.txt (line 1)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from jsonschema<5,>=4.21.1->composio-core==0.7.1->langflow->-r requirements.txt (line 1)) (0.23.1)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 3)) (23.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 3)) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 3)) (0.5.3)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 3)) (2.0.15)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 3)) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 3)) (0.18.1)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 3)) (2.17.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.22->langchain==0.3.10->langflow->-r requirements.txt (line 1)) (1.33)\n",
      "Collecting pytest<9,>=7 (from langchain-tests<0.4.0,>=0.3.7->langchain-pinecone==0.2.2->langflow->-r requirements.txt (line 1))\n",
      "  Using cached pytest-8.3.5-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting pytest-asyncio<1,>=0.20 (from langchain-tests<0.4.0,>=0.3.7->langchain-pinecone==0.2.2->langflow->-r requirements.txt (line 1))\n",
      "  Using cached pytest_asyncio-0.25.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting syrupy<5,>=4 (from langchain-tests<0.4.0,>=0.3.7->langchain-pinecone==0.2.2->langflow->-r requirements.txt (line 1))\n",
      "  Using cached syrupy-4.9.0-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting pytest-socket<1,>=0.6.0 (from langchain-tests<0.4.0,>=0.3.7->langchain-pinecone==0.2.2->langflow->-r requirements.txt (line 1))\n",
      "  Using cached pytest_socket-0.7.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting win32-setctime>=1.0.0 (from loguru<1.0.0,>=0.7.1->langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached win32_setctime-1.2.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting cattrs!=23.2.1 (from lsprotocol<2024.0.0,>=2023.0.1->astra-assistants~=2.2.9->astra-assistants[tools]~=2.2.9->langflow->-r requirements.txt (line 1))\n",
      "  Using cached cattrs-24.1.2-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting dill>=0.3.9 (from multiprocess<1.0.0,>=0.70.14->langflow-base==0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from nbformat>=5.7->nbconvert->jupyter->-r requirements.txt (line 3)) (2.21.1)\n",
      "INFO: pip is looking at multiple versions of ollama to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting ollama<1,>=0.4.4 (from langchain-ollama<1.0.0,>=0.2.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached ollama-0.4.6-py3-none-any.whl.metadata (4.7 kB)\n",
      "  Using cached ollama-0.4.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "  Using cached ollama-0.4.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.7 (from langchain~=0.3.3->langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_text_splitters-0.3.7-py3-none-any.whl.metadata (1.9 kB)\n",
      "INFO: pip is still looking at multiple versions of ollama to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-tests<1.0.0,>=0.3.7 (from langchain-pinecone<1.0.0,>=0.1.3->langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_tests-0.3.14-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting langchain-experimental<1.0.0,>=0.0.61 (from langflow-base==0.1.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_experimental-0.3.3-py3-none-any.whl.metadata (1.7 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting langchain-core~=0.3.15 (from langflow-base==0.1.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached langchain_core-0.3.47-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting groq<1,>=0.4.1 (from langchain-groq<1.0.0,>=0.1.9->langflow->-r requirements.txt (line 1))\n",
      "  Using cached groq-0.19.0-py3-none-any.whl.metadata (15 kB)\n",
      "  Using cached groq-0.18.0-py3-none-any.whl.metadata (14 kB)\n",
      "  Using cached groq-0.17.0-py3-none-any.whl.metadata (14 kB)\n",
      "  Using cached groq-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "  Using cached groq-0.15.0-py3-none-any.whl.metadata (14 kB)\n",
      "  Using cached groq-0.14.0-py3-none-any.whl.metadata (14 kB)\n",
      "  Using cached groq-0.13.1-py3-none-any.whl.metadata (14 kB)\n",
      "  Using cached groq-0.13.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached groq-0.12.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached groq-0.11.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached groq-0.10.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached groq-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached groq-0.8.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached groq-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached groq-0.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached groq-0.5.0-py3-none-any.whl.metadata (12 kB)\n",
      "  Using cached groq-0.4.2-py3-none-any.whl.metadata (12 kB)\n",
      "  Using cached groq-0.4.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting gotrue<3.0,>=1.3 (from supabase==2.6.0->langflow->-r requirements.txt (line 1))\n",
      "  Using cached gotrue-2.11.3-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.11.2-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.11.1-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.11.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.10.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.9.3-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.9.2-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.9.1-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.9.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.8.1-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.8.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.7.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.6.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "  Using cached gotrue-2.6.1-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.6.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.5.5-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.5.4-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.5.3-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.5.2-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.5.1-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.5.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.4.4-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.4.3-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.4.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "  Using cached gotrue-2.4.1-py3-none-any.whl.metadata (6.0 kB)\n",
      "INFO: pip is looking at multiple versions of gotrue to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached gotrue-2.1.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached gotrue-2.0.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached gotrue-1.3.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached gotrue-1.3.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting e2b-code-interpreter<2.0.0,>=1.0.1 (from astra-assistants[tools]~=2.2.9->langflow->-r requirements.txt (line 1))\n",
      "  Using cached e2b_code_interpreter-1.1.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting google-cloud-aiplatform<2.0.0,>=1.70.0 (from langchain-google-vertexai==2.0.7->langflow->-r requirements.txt (line 1))\n",
      "  Using cached google_cloud_aiplatform-1.84.0-py2.py3-none-any.whl.metadata (33 kB)\n",
      "Collecting shapely<3.0.0dev (from google-cloud-aiplatform<2.0.0,>=1.70.0->langchain-google-vertexai==2.0.7->langflow->-r requirements.txt (line 1))\n",
      "  Using cached shapely-2.1.0rc1-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
      "Collecting google-cloud-aiplatform<2.0.0,>=1.70.0 (from langchain-google-vertexai==2.0.7->langflow->-r requirements.txt (line 1))\n",
      "  Using cached google_cloud_aiplatform-1.83.0-py2.py3-none-any.whl.metadata (33 kB)\n",
      "  Using cached google_cloud_aiplatform-1.82.0-py2.py3-none-any.whl.metadata (33 kB)\n",
      "  Using cached google_cloud_aiplatform-1.81.0-py2.py3-none-any.whl.metadata (32 kB)\n",
      "  Using cached google_cloud_aiplatform-1.80.0-py2.py3-none-any.whl.metadata (32 kB)\n",
      "  Using cached google_cloud_aiplatform-1.79.0-py2.py3-none-any.whl.metadata (32 kB)\n",
      "  Using cached google_cloud_aiplatform-1.78.0-py2.py3-none-any.whl.metadata (31 kB)\n",
      "  Using cached google_cloud_aiplatform-1.77.0-py2.py3-none-any.whl.metadata (31 kB)\n",
      "  Using cached google_cloud_aiplatform-1.76.0-py2.py3-none-any.whl.metadata (31 kB)\n",
      "  Using cached google_cloud_aiplatform-1.75.0-py2.py3-none-any.whl.metadata (31 kB)\n",
      "  Using cached google_cloud_aiplatform-1.74.0-py2.py3-none-any.whl.metadata (31 kB)\n",
      "  Using cached google_cloud_aiplatform-1.73.0-py2.py3-none-any.whl.metadata (31 kB)\n",
      "  Using cached google_cloud_aiplatform-1.72.0-py2.py3-none-any.whl.metadata (31 kB)\n",
      "  Using cached google_cloud_aiplatform-1.71.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "  Using cached google_cloud_aiplatform-1.71.0-py2.py3-none-any.whl.metadata (32 kB)\n",
      "  Using cached google_cloud_aiplatform-1.70.0-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting fastapi-pagination<1.0.0,>=0.12.29 (from langflow-base==0.1.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached fastapi_pagination-0.12.33-py3-none-any.whl.metadata (6.4 kB)\n",
      "  Using cached fastapi_pagination-0.12.32-py3-none-any.whl.metadata (6.3 kB)\n",
      "  Using cached fastapi_pagination-0.12.31-py3-none-any.whl.metadata (6.3 kB)\n",
      "  Using cached fastapi_pagination-0.12.30-py3-none-any.whl.metadata (6.3 kB)\n",
      "  Using cached fastapi_pagination-0.12.29-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting fastapi<1.0.0,>=0.115.2 (from langflow-base==0.1.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached fastapi-0.115.10-py3-none-any.whl.metadata (27 kB)\n",
      "  Using cached fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting starlette<0.46.0,>=0.40.0 (from fastapi<1.0.0,>=0.115.2->langflow-base==0.1.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting fastapi<1.0.0,>=0.115.2 (from langflow-base==0.1.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
      "  Using cached fastapi-0.115.7-py3-none-any.whl.metadata (27 kB)\n",
      "  Using cached fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting starlette<0.42.0,>=0.40.0 (from fastapi<1.0.0,>=0.115.2->langflow-base==0.1.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting fastapi<1.0.0,>=0.115.2 (from langflow-base==0.1.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n",
      "  Using cached fastapi-0.115.4-py3-none-any.whl.metadata (27 kB)\n",
      "  Using cached fastapi-0.115.3-py3-none-any.whl.metadata (27 kB)\n",
      "  Using cached fastapi-0.115.2-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting starlette<0.41.0,>=0.37.2 (from fastapi<1.0.0,>=0.115.2->langflow-base==0.1.1->langflow->-r requirements.txt (line 1))\n",
      "  Using cached starlette-0.40.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "INFO: pip is still looking at multiple versions of gotrue to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting e2b-code-interpreter<2.0.0,>=1.0.1 (from astra-assistants[tools]~=2.2.9->langflow->-r requirements.txt (line 1))\n",
      "  Using cached e2b_code_interpreter-1.0.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\praga\\AI_Agents_Bootcamp\\.venv\\Lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 106, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\praga\\AI_Agents_Bootcamp\\.venv\\Lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 97, in _inner_run\n",
      "    return self.run(options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\praga\\AI_Agents_Bootcamp\\.venv\\Lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\praga\\AI_Agents_Bootcamp\\.venv\\Lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 386, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "                      ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\praga\\AI_Agents_Bootcamp\\.venv\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 95, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "                            ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\praga\\AI_Agents_Bootcamp\\.venv\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 546, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\praga\\AI_Agents_Bootcamp\\.venv\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 457, in resolve\n",
      "    raise ResolutionTooDeep(max_rounds)\n",
      "pip._vendor.resolvelib.resolvers.ResolutionTooDeep: 200000\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24ee1d6",
   "metadata": {},
   "source": [
    "### 🔹 Option 2: Install manually (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f73b8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d52f2175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langflow\n",
      "  Using cached langflow-1.2.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting ag2>=0.1.0 (from langflow)\n",
      "  Using cached ag2-0.8.3-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting aiofile<4.0.0,>=3.9.0 (from langflow)\n",
      "  Using cached aiofile-3.9.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting apify-client>=1.8.1 (from langflow)\n",
      "  Using cached apify_client-1.9.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting arize-phoenix-otel>=0.6.1 (from langflow)\n",
      "  Using cached arize_phoenix_otel-0.9.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting assemblyai==0.35.1 (from langflow)\n",
      "  Using cached assemblyai-0.35.1-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting astra-assistants~=2.2.9 (from astra-assistants[tools]~=2.2.9->langflow)\n",
      "  Using cached astra_assistants-2.2.11-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting atlassian-python-api==3.41.16 (from langflow)\n",
      "  Using cached atlassian_python_api-3.41.16-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting beautifulsoup4==4.12.3 (from langflow)\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting boto3==1.34.162 (from langflow)\n",
      "  Using cached boto3-1.34.162-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting certifi<2025.0.0,>=2023.11.17 (from langflow)\n",
      "  Using cached certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting chromadb==0.5.23 (from langflow)\n",
      "  Using cached chromadb-0.5.23-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting composio-core==0.7.1 (from langflow)\n",
      "  Using cached composio_core-0.7.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting composio-langchain==0.7.1 (from langflow)\n",
      "  Using cached composio_langchain-0.7.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting crewai==0.102.0 (from langflow)\n",
      "  Using cached crewai-0.102.0-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting dspy-ai==2.5.41 (from langflow)\n",
      "  Using cached dspy_ai-2.5.41-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting duckduckgo-search==7.2.1 (from langflow)\n",
      "  Using cached duckduckgo_search-7.2.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting elasticsearch==8.16.0 (from langflow)\n",
      "  Using cached elasticsearch-8.16.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting faiss-cpu==1.9.0.post1 (from langflow)\n",
      "  Using cached faiss_cpu-1.9.0.post1-cp312-cp312-win_amd64.whl.metadata (4.5 kB)\n",
      "Collecting fake-useragent==1.5.1 (from langflow)\n",
      "  Using cached fake_useragent-1.5.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting fastavro==1.9.7 (from langflow)\n",
      "  Using cached fastavro-1.9.7-cp312-cp312-win_amd64.whl.metadata (5.6 kB)\n",
      "Collecting gitpython==3.1.43 (from langflow)\n",
      "  Using cached GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting google-api-python-client==2.154.0 (from langflow)\n",
      "  Using cached google_api_python_client-2.154.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting google-search-results<3.0.0,>=2.4.1 (from langflow)\n",
      "  Using cached google_search_results-2.4.2.tar.gz (18 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting huggingface-hub<1.0.0,>=0.23.2 (from huggingface-hub[inference]<1.0.0,>=0.23.2->langflow)\n",
      "  Using cached huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting jq==1.8.0 (from langflow)\n",
      "  Using cached jq-1.8.0-cp312-cp312-win_amd64.whl.metadata (7.2 kB)\n",
      "Collecting json-repair==0.30.3 (from langflow)\n",
      "  Using cached json_repair-0.30.3-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting kubernetes==31.0.0 (from langflow)\n",
      "  Using cached kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting langchain-anthropic==0.3.0 (from langflow)\n",
      "  Using cached langchain_anthropic-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langchain-astradb==0.5.2 (from langflow)\n",
      "  Using cached langchain_astradb-0.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting langchain-aws==0.2.7 (from langflow)\n",
      "  Using cached langchain_aws-0.2.7-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting langchain-chroma==0.1.4 (from langflow)\n",
      "  Using cached langchain_chroma-0.1.4-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting langchain-cohere==0.3.3 (from langflow)\n",
      "  Using cached langchain_cohere-0.3.3-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting langchain-community~=0.3.10 (from langflow)\n",
      "  Using cached langchain_community-0.3.20-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting langchain-elasticsearch==0.3.0 (from langflow)\n",
      "  Using cached langchain_elasticsearch-0.3.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting langchain-google-calendar-tools==0.0.1 (from langflow)\n",
      "  Using cached langchain_google_calendar_tools-0.0.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting langchain-google-community==2.0.3 (from langflow)\n",
      "  Using cached langchain_google_community-2.0.3-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting langchain-google-genai==2.0.6 (from langflow)\n",
      "  Using cached langchain_google_genai-2.0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting langchain-google-vertexai==2.0.7 (from langflow)\n",
      "  Using cached langchain_google_vertexai-2.0.7-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting langchain-groq==0.2.1 (from langflow)\n",
      "  Using cached langchain_groq-0.2.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain-milvus==0.1.7 (from langflow)\n",
      "  Using cached langchain_milvus-0.1.7-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langchain-mistralai==0.2.3 (from langflow)\n",
      "  Using cached langchain_mistralai-0.2.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting langchain-mongodb==0.2.0 (from langflow)\n",
      "  Using cached langchain_mongodb-0.2.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting langchain-nvidia-ai-endpoints==0.3.8 (from langflow)\n",
      "  Using cached langchain_nvidia_ai_endpoints-0.3.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting langchain-ollama==0.2.1 (from langflow)\n",
      "  Using cached langchain_ollama-0.2.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langchain-openai==0.2.12 (from langflow)\n",
      "  Using cached langchain_openai-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting langchain-pinecone==0.2.2 (from langflow)\n",
      "  Using cached langchain_pinecone-0.2.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting langchain-sambanova==0.1.0 (from langflow)\n",
      "  Using cached langchain_sambanova-0.1.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting langchain-unstructured==0.1.5 (from langflow)\n",
      "  Using cached langchain_unstructured-0.1.5-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting langchain==0.3.10 (from langflow)\n",
      "  Using cached langchain-0.3.10-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langflow-base==0.2.0 (from langflow)\n",
      "  Using cached langflow_base-0.2.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting langfuse==2.53.9 (from langflow)\n",
      "  Using cached langfuse-2.53.9-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting langsmith==0.1.147 (from langflow)\n",
      "  Using cached langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langwatch==0.1.16 (from langflow)\n",
      "  Using cached langwatch-0.1.16-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting lark==1.2.2 (from langflow)\n",
      "  Using cached lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting litellm==1.60.2 (from langflow)\n",
      "  Using cached litellm-1.60.2-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting markdown==3.7 (from langflow)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: markupsafe==3.0.2 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from langflow) (3.0.2)\n",
      "Collecting mcp>=0.9.1 (from langflow)\n",
      "  Using cached mcp-1.5.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting mem0ai==0.1.34 (from langflow)\n",
      "  Using cached mem0ai-0.1.34-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting metal-sdk==2.5.1 (from langflow)\n",
      "  Using cached metal_sdk-2.5.1-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting metaphor-python==0.1.23 (from langflow)\n",
      "  Using cached metaphor_python-0.1.23-py3-none-any.whl.metadata (636 bytes)\n",
      "Collecting needle-python>=0.4.0 (from langflow)\n",
      "  Using cached needle_python-0.4.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting networkx==3.4.2 (from langflow)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting nltk==3.9.1 (from langflow)\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting numexpr==2.10.2 (from langflow)\n",
      "  Using cached numexpr-2.10.2-cp312-cp312-win_amd64.whl.metadata (8.3 kB)\n",
      "Collecting openinference-instrumentation-langchain>=0.1.29 (from langflow)\n",
      "  Using cached openinference_instrumentation_langchain-0.1.37-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting opensearch-py==2.8.0 (from langflow)\n",
      "  Using cached opensearch_py-2.8.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting pgvector==0.3.6 (from langflow)\n",
      "  Using cached pgvector-0.3.6-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pyarrow==19.0.0 (from langflow)\n",
      "  Using cached pyarrow-19.0.0-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting pydantic-ai>=0.0.19 (from langflow)\n",
      "  Using cached pydantic_ai-0.0.43-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pydantic-settings==2.4.0 (from langflow)\n",
      "  Using cached pydantic_settings-2.4.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting pymongo==4.10.1 (from langflow)\n",
      "  Using cached pymongo-4.10.1-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "Collecting pytube==15.0.0 (from langflow)\n",
      "  Using cached pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting pywin32==307 (from langflow)\n",
      "  Using cached pywin32-307-cp312-cp312-win_amd64.whl.metadata (8.3 kB)\n",
      "Collecting qdrant-client==1.9.2 (from langflow)\n",
      "  Using cached qdrant_client-1.9.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting qianfan==0.3.5 (from langflow)\n",
      "  Using cached qianfan-0.3.5-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting ragstack-ai-knowledge-store==0.2.1 (from langflow)\n",
      "  Using cached ragstack_ai_knowledge_store-0.2.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting redis==5.2.1 (from langflow)\n",
      "  Using cached redis-5.2.1-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting scrapegraph-py>=1.12.0 (from langflow)\n",
      "  Using cached scrapegraph_py-1.12.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting smolagents>=1.8.0 (from langflow)\n",
      "  Using cached smolagents-1.12.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting spider-client==0.1.24 (from langflow)\n",
      "  Using cached spider-client-0.1.24.tar.gz (15 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=2.0.38 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from sqlalchemy[aiosqlite,postgresql-psycopg2binary,postgresql-psycopgbinary]<3.0.0,>=2.0.38->langflow) (2.0.39)\n",
      "Collecting sseclient-py==1.8.0 (from langflow)\n",
      "  Using cached sseclient_py-1.8.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting supabase==2.6.0 (from langflow)\n",
      "  Using cached supabase-2.6.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting types-cachetools==5.5.0.20240820 (from langflow)\n",
      "  Using cached types_cachetools-5.5.0.20240820-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting upstash-vector==0.6.0 (from langflow)\n",
      "  Using cached upstash_vector-0.6.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting uv>=0.5.7 (from langflow)\n",
      "  Using cached uv-0.6.9-py3-none-win_amd64.whl.metadata (11 kB)\n",
      "Collecting weaviate-client==4.10.2 (from langflow)\n",
      "  Using cached weaviate_client-4.10.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting wikipedia==1.4.0 (from langflow)\n",
      "  Using cached wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting wolframalpha==5.1.3 (from langflow)\n",
      "  Using cached wolframalpha-5.1.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting yfinance==0.2.50 (from langflow)\n",
      "  Using cached yfinance-0.2.50-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting youtube-transcript-api==0.6.3 (from langflow)\n",
      "  Using cached youtube_transcript_api-0.6.3-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting zep-python==2.0.2 (from langflow)\n",
      "  Using cached zep_python-2.0.2-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: httpx>=0.19.0 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from assemblyai==0.35.1->langflow) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=1.10.17 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from assemblyai==0.35.1->langflow) (2.10.6)\n",
      "Requirement already satisfied: typing-extensions>=3.7 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from assemblyai==0.35.1->langflow) (4.12.2)\n",
      "Collecting websockets>=11.0 (from assemblyai==0.35.1->langflow)\n",
      "  Using cached websockets-15.0.1-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
      "Collecting deprecated (from atlassian-python-api==3.41.16->langflow)\n",
      "  Using cached Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from atlassian-python-api==3.41.16->langflow) (2.32.3)\n",
      "Requirement already satisfied: six in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from atlassian-python-api==3.41.16->langflow) (1.17.0)\n",
      "Collecting oauthlib (from atlassian-python-api==3.41.16->langflow)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting requests-oauthlib (from atlassian-python-api==3.41.16->langflow)\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting jmespath (from atlassian-python-api==3.41.16->langflow)\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from beautifulsoup4==4.12.3->langflow) (2.6)\n",
      "Collecting botocore<1.35.0,>=1.34.162 (from boto3==1.34.162->langflow)\n",
      "  Using cached botocore-1.34.162-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3==1.34.162->langflow)\n",
      "  Using cached s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting build>=1.0.3 (from chromadb==0.5.23->langflow)\n",
      "  Using cached build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb==0.5.23->langflow)\n",
      "  Using cached chroma_hnswlib-0.7.6.tar.gz (32 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting fastapi>=0.95.2 (from chromadb==0.5.23->langflow)\n",
      "  Using cached fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb==0.5.23->langflow)\n",
      "  Using cached uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting numpy>=1.22.5 (from chromadb==0.5.23->langflow)\n",
      "  Using cached numpy-2.2.4-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting posthog>=2.4.0 (from chromadb==0.5.23->langflow)\n",
      "  Using cached posthog-3.21.0-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb==0.5.23->langflow)\n",
      "  Using cached onnxruntime-1.21.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb==0.5.23->langflow)\n",
      "  Using cached opentelemetry_api-1.31.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb==0.5.23->langflow)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.31.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb==0.5.23->langflow)\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.52b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb==0.5.23->langflow)\n",
      "  Using cached opentelemetry_sdk-1.31.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting tokenizers<=0.20.3,>=0.13.2 (from chromadb==0.5.23->langflow)\n",
      "  Using cached tokenizers-0.20.3-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb==0.5.23->langflow)\n",
      "  Using cached PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting tqdm>=4.65.0 (from chromadb==0.5.23->langflow)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from chromadb==0.5.23->langflow) (7.7.0)\n",
      "Collecting importlib-resources (from chromadb==0.5.23->langflow)\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb==0.5.23->langflow)\n",
      "  Using cached grpcio-1.71.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb==0.5.23->langflow)\n",
      "  Using cached bcrypt-4.3.0-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb==0.5.23->langflow)\n",
      "  Using cached typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from chromadb==0.5.23->langflow) (9.0.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from chromadb==0.5.23->langflow) (6.0.2)\n",
      "Collecting mmh3>=4.0.1 (from chromadb==0.5.23->langflow)\n",
      "  Using cached mmh3-5.1.0-cp312-cp312-win_amd64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from chromadb==0.5.23->langflow) (3.10.15)\n",
      "Collecting rich>=10.11.0 (from chromadb==0.5.23->langflow)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting aiohttp (from composio-core==0.7.1->langflow)\n",
      "  Using cached aiohttp-3.11.14-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: jsonschema<5,>=4.21.1 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from composio-core==0.7.1->langflow) (4.23.0)\n",
      "Collecting sentry-sdk>=2.0.0 (from composio-core==0.7.1->langflow)\n",
      "  Using cached sentry_sdk-2.24.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pysher==1.0.8 (from composio-core==0.7.1->langflow)\n",
      "  Using cached Pysher-1.0.8.tar.gz (9.1 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting importlib-metadata>=4.8.1 (from composio-core==0.7.1->langflow)\n",
      "  Using cached importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting jsonref>=1.1.0 (from composio-core==0.7.1->langflow)\n",
      "  Using cached jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting inflection>=0.5.1 (from composio-core==0.7.1->langflow)\n",
      "  Using cached inflection-0.5.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting semver>=2.13.0 (from composio-core==0.7.1->langflow)\n",
      "  Using cached semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting click (from composio-core==0.7.1->langflow)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyperclip<2,>=1.8.2 (from composio-core==0.7.1->langflow)\n",
      "  Using cached pyperclip-1.9.0.tar.gz (20 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting paramiko>=3.4.1 (from composio-core==0.7.1->langflow)\n",
      "  Using cached paramiko-3.5.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langchainhub>=0.1.15 (from composio-langchain==0.7.1->langflow)\n",
      "  Using cached langchainhub-0.1.21-py3-none-any.whl.metadata (659 bytes)\n",
      "Collecting appdirs>=1.4.4 (from crewai==0.102.0->langflow)\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting auth0-python>=4.7.1 (from crewai==0.102.0->langflow)\n",
      "  Using cached auth0_python-4.8.1-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting blinker>=1.9.0 (from crewai==0.102.0->langflow)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting instructor>=1.3.3 (from crewai==0.102.0->langflow)\n",
      "  Using cached instructor-1.7.7-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: json5>=0.10.0 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from crewai==0.102.0->langflow) (0.10.0)\n",
      "Collecting openai>=1.13.3 (from crewai==0.102.0->langflow)\n",
      "  Using cached openai-1.68.2-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting openpyxl>=3.1.5 (from crewai==0.102.0->langflow)\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http>=1.22.0 (from crewai==0.102.0->langflow)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_http-1.31.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting pdfplumber>=0.11.4 (from crewai==0.102.0->langflow)\n",
      "  Using cached pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n",
      "Requirement already satisfied: python-dotenv>=1.0.0 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from crewai==0.102.0->langflow) (1.0.1)\n",
      "Collecting pyvis>=0.3.2 (from crewai==0.102.0->langflow)\n",
      "  Using cached pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting regex>=2024.9.11 (from crewai==0.102.0->langflow)\n",
      "  Using cached regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tomli-w>=1.1.0 (from crewai==0.102.0->langflow)\n",
      "  Using cached tomli_w-1.2.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting tomli>=2.0.2 (from crewai==0.102.0->langflow)\n",
      "  Using cached tomli-2.2.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting dspy>=2.5.3 (from dspy-ai==2.5.41->langflow)\n",
      "  Using cached dspy-2.6.14-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting primp>=0.10.0 (from duckduckgo-search==7.2.1->langflow)\n",
      "  Using cached primp-0.14.0-cp38-abi3-win_amd64.whl.metadata (13 kB)\n",
      "Collecting lxml>=5.3.0 (from duckduckgo-search==7.2.1->langflow)\n",
      "  Using cached lxml-5.3.1-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting elastic-transport<9,>=8.15.1 (from elasticsearch==8.16.0->langflow)\n",
      "  Using cached elastic_transport-8.17.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from faiss-cpu==1.9.0.post1->langflow) (24.2)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython==3.1.43->langflow)\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client==2.154.0->langflow)\n",
      "  Using cached httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 (from google-api-python-client==2.154.0->langflow)\n",
      "  Using cached google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client==2.154.0->langflow)\n",
      "  Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 (from google-api-python-client==2.154.0->langflow)\n",
      "  Using cached google_api_core-2.24.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client==2.154.0->langflow)\n",
      "  Using cached uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from kubernetes==31.0.0->langflow) (2.9.0.post0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from kubernetes==31.0.0->langflow) (1.8.0)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from kubernetes==31.0.0->langflow) (2.3.0)\n",
      "Collecting durationpy>=0.7 (from kubernetes==31.0.0->langflow)\n",
      "  Using cached durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.22 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from langchain==0.3.10->langflow) (0.3.47)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from langchain==0.3.10->langflow) (0.3.7)\n",
      "Collecting anthropic<1,>=0.39.0 (from langchain-anthropic==0.3.0->langflow)\n",
      "  Using cached anthropic-0.49.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from langchain-anthropic==0.3.0->langflow) (0.7.1)\n",
      "Collecting astrapy<2.0.0,>=1.5.2 (from langchain-astradb==0.5.2->langflow)\n",
      "  Using cached astrapy-1.5.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.22.5 (from chromadb==0.5.23->langflow)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Collecting cohere<6.0,>=5.5.6 (from langchain-cohere==0.3.3->langflow)\n",
      "  Using cached cohere-5.14.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting langchain-experimental<0.4.0,>=0.3.0 (from langchain-cohere==0.3.3->langflow)\n",
      "  Using cached langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting pandas>=1.4.3 (from langchain-cohere==0.3.3->langflow)\n",
      "  Using cached pandas-2.2.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting tabulate<0.10.0,>=0.9.0 (from langchain-cohere==0.3.3->langflow)\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting google-auth-oauthlib>=1.1.0 (from langchain-google-calendar-tools==0.0.1->langflow)\n",
      "  Using cached google_auth_oauthlib-1.2.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting protobuf>=4.25.0 (from langchain-google-calendar-tools==0.0.1->langflow)\n",
      "  Using cached protobuf-6.30.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting pytz>=2023.3.post1 (from langchain-google-calendar-tools==0.0.1->langflow)\n",
      "  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting google-cloud-core<3.0.0,>=2.4.1 (from langchain-google-community==2.0.3->langflow)\n",
      "  Using cached google_cloud_core-2.4.3-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai==2.0.6->langflow)\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting google-generativeai<0.9.0,>=0.8.0 (from langchain-google-genai==2.0.6->langflow)\n",
      "  Using cached google_generativeai-0.8.4-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting google-cloud-aiplatform<2.0.0,>=1.70.0 (from langchain-google-vertexai==2.0.7->langflow)\n",
      "  Using cached google_cloud_aiplatform-1.85.0-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting google-cloud-storage<3.0.0,>=2.18.0 (from langchain-google-vertexai==2.0.7->langflow)\n",
      "  Using cached google_cloud_storage-2.19.0-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting httpx>=0.19.0 (from assemblyai==0.35.1->langflow)\n",
      "  Using cached httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-google-vertexai==2.0.7->langflow)\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting groq<1,>=0.4.1 (from langchain-groq==0.2.1->langflow)\n",
      "  Using cached groq-0.20.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pymilvus<3.0.0,>=2.4.3 (from langchain-milvus==0.1.7->langflow)\n",
      "  Using cached pymilvus-2.5.6-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting ollama<1,>=0.3.0 (from langchain-ollama==0.2.1->langflow)\n",
      "  Using cached ollama-0.4.7-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai==0.2.12->langflow)\n",
      "  Using cached tiktoken-0.9.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting aiohttp (from composio-core==0.7.1->langflow)\n",
      "  Using cached aiohttp-3.10.11-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting langchain-tests<0.4.0,>=0.3.7 (from langchain-pinecone==0.2.2->langflow)\n",
      "  Using cached langchain_tests-0.3.15-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting pinecone<6.0.0,>=5.4.0 (from langchain-pinecone==0.2.2->langflow)\n",
      "  Using cached pinecone-5.4.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting types-requests (from langchain-sambanova==0.1.0->langflow)\n",
      "  Using cached types_requests-2.32.0.20250306-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting unstructured-client<0.26.0,>=0.25.0 (from langchain-unstructured==0.1.5->langflow)\n",
      "  Using cached unstructured_client-0.25.9-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting aiofiles<25.0.0,>=24.1.0 (from langflow-base==0.2.0->langflow)\n",
      "  Using cached aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting aiosqlite>=0.20.0 (from langflow-base==0.2.0->langflow)\n",
      "  Using cached aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting alembic<2.0.0,>=1.13.0 (from langflow-base==0.2.0->langflow)\n",
      "  Using cached alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting asyncer<1.0.0,>=0.0.5 (from langflow-base==0.2.0->langflow)\n",
      "  Using cached asyncer-0.0.8-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb==0.5.23->langflow)\n",
      "  Using cached bcrypt-4.0.1-cp36-abi3-win_amd64.whl.metadata (9.0 kB)\n",
      "Collecting cachetools<6.0.0,>=5.5.0 (from langflow-base==0.2.0->langflow)\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting chardet<6.0.0,>=5.2.0 (from langflow-base==0.2.0->langflow)\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting clickhouse-connect==0.7.19 (from langflow-base==0.2.0->langflow)\n",
      "  Using cached clickhouse_connect-0.7.19-cp312-cp312-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting cryptography<44.0.0,>=42.0.5 (from langflow-base==0.2.0->langflow)\n",
      "  Using cached cryptography-43.0.3-cp39-abi3-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting diskcache<6.0.0,>=5.6.3 (from langflow-base==0.2.0->langflow)\n",
      "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting docstring-parser<1.0.0,>=0.16 (from langflow-base==0.2.0->langflow)\n",
      "  Using cached docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting duckdb<2.0.0,>=1.0.0 (from langflow-base==0.2.0->langflow)\n",
      "  Using cached duckdb-1.2.1-cp312-cp312-win_amd64.whl.metadata (995 bytes)\n",
      "Collecting emoji<3.0.0,>=2.12.0 (from langflow-base==0.2.0->langflow)\n",
      "  Using cached emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting fastapi-pagination<1.0.0,>=0.12.29 (from langflow-base==0.2.0->langflow)\n",
      "  Using cached fastapi_pagination-0.12.34-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting filelock<4.0.0,>=3.15.4 (from langflow-base==0.2.0->langflow)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting firecrawl-py<2.0.0,>=1.0.16 (from langflow-base==0.2.0->langflow)\n",
      "  Using cached firecrawl_py-1.14.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting grandalf<1.0.0,>=0.8.0 (from langflow-base==0.2.0->langflow)\n",
      "  Using cached grandalf-0.8-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: greenlet>=3.1.1 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from langflow-base==0.2.0->langflow) (3.1.1)\n",
      "Collecting gunicorn<24.0.0,>=22.0.0 (from langflow-base==0.2.0->langflow)\n",
      "  Using cached gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting loguru<1.0.0,>=0.7.1 (from langflow-base==0.2.0->langflow)\n",
      "  Using cached loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting multiprocess<1.0.0,>=0.70.14 (from langflow-base==0.2.0->langflow)\n",
      "  Using cached multiprocess-0.70.17-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting nanoid<3.0.0,>=2.0.0 (from langflow-base==0.2.0->langflow)\n",
      "  Using cached nanoid-2.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.6.0 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from langflow-base==0.2.0->langflow) (1.6.0)\n",
      "Collecting opentelemetry-exporter-prometheus<1.0.0,>=0.46b0 (from langflow-base==0.2.0->langflow)\n",
      "  Using cached opentelemetry_exporter_prometheus-0.52b1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting passlib<2.0.0,>=1.7.4 (from langflow-base==0.2.0->langflow)\n",
      "  Using cached passlib-1.7.4-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting pillow<12.0.0,>=11.1.0 (from langflow-base==0.2.0->langflow)\n",
      "  Using cached pillow-11.1.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=4.2.0 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from langflow-base==0.2.0->langflow) (4.3.7)\n",
      "Requirement already satisfied: prometheus-client<1.0.0,>=0.20.0 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from langflow-base==0.2.0->langflow) (0.21.1)\n",
      "Collecting pypdf~=5.1.0 (from langflow-base==0.2.0->langflow)\n",
      "  Using cached pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting python-docx<2.0.0,>=1.1.0 (from langflow-base==0.2.0->langflow)\n",
      "  Using cached python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting python-jose<4.0.0,>=3.3.0 (from langflow-base==0.2.0->langflow)\n",
      "  Using cached python_jose-3.4.0-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting python-multipart<1.0.0,>=0.0.12 (from langflow-base==0.2.0->langflow)\n",
      "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting setuptools<76.0.0,>=70 (from langflow-base==0.2.0->langflow)\n",
      "  Using cached setuptools-75.9.1-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting sqlmodel==0.0.22 (from langflow-base==0.2.0->langflow)\n",
      "  Using cached sqlmodel-0.0.22-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting uncurl<1.0.0,>=0.0.11 (from langflow-base==0.2.0->langflow)\n",
      "  Using cached uncurl-0.0.11-py3-none-any.whl.metadata (300 bytes)\n",
      "Collecting validators>=0.34.0 (from langflow-base==0.2.0->langflow)\n",
      "  Using cached validators-0.34.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.4.0 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from langfuse==2.53.9->langflow) (4.9.0)\n",
      "Collecting backoff>=1.10.0 (from langfuse==2.53.9->langflow)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: idna<4.0,>=3.7 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from langfuse==2.53.9->langflow) (3.10)\n",
      "Collecting wrapt<2.0,>=1.14 (from langfuse==2.53.9->langflow)\n",
      "  Using cached wrapt-1.17.2-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from langsmith==0.1.147->langflow) (1.0.0)\n",
      "Collecting coolname<3.0.0,>=2.2.0 (from langwatch==0.1.16->langflow)\n",
      "  Using cached coolname-2.2.0-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting retry<0.10.0,>=0.9.2 (from langwatch==0.1.16->langflow)\n",
      "  Using cached retry-0.9.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from litellm==1.60.2->langflow) (3.1.6)\n",
      "Collecting pytz>=2023.3.post1 (from langchain-google-calendar-tools==0.0.1->langflow)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting joblib (from nltk==3.9.1->langflow)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting Events (from opensearch-py==2.8.0->langflow)\n",
      "  Using cached Events-0.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo==4.10.1->langflow)\n",
      "  Using cached dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting grpcio-tools>=1.41.0 (from qdrant-client==1.9.2->langflow)\n",
      "  Using cached grpcio_tools-1.71.0-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client==1.9.2->langflow)\n",
      "  Using cached portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting aiolimiter>=1.1.0 (from qianfan==0.3.5->langflow)\n",
      "  Using cached aiolimiter-1.2.1-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting bce-python-sdk>=0.8.79 (from qianfan==0.3.5->langflow)\n",
      "  Using cached bce_python_sdk-0.9.29-py3-none-any.whl.metadata (416 bytes)\n",
      "Collecting clevercsv (from qianfan==0.3.5->langflow)\n",
      "  Using cached clevercsv-0.8.3-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting ijson (from qianfan==0.3.5->langflow)\n",
      "  Using cached ijson-3.3.0-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.38 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from qianfan==0.3.5->langflow) (3.0.50)\n",
      "Collecting tenacity>=8.2.3 (from chromadb==0.5.23->langflow)\n",
      "  Using cached tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting cassio<0.2.0,>=0.1.7 (from ragstack-ai-knowledge-store==0.2.1->langflow)\n",
      "  Using cached cassio-0.1.10-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting gotrue<3.0,>=1.3 (from supabase==2.6.0->langflow)\n",
      "  Using cached gotrue-2.11.4-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting postgrest<0.17.0,>=0.14 (from supabase==2.6.0->langflow)\n",
      "  Using cached postgrest-0.16.11-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting realtime<2.0.0,>=1.0.0 (from supabase==2.6.0->langflow)\n",
      "  Using cached realtime-1.0.6-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting storage3<0.8.0,>=0.5.3 (from supabase==2.6.0->langflow)\n",
      "  Using cached storage3-0.7.7-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting supafunc<0.6.0,>=0.3.1 (from supabase==2.6.0->langflow)\n",
      "  Using cached supafunc-0.5.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting authlib<1.3.2,>=1.2.1 (from weaviate-client==4.10.2->langflow)\n",
      "  Using cached Authlib-1.3.1-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting grpcio-health-checking<2.0.0,>=1.66.2 (from weaviate-client==4.10.2->langflow)\n",
      "  Using cached grpcio_health_checking-1.71.0-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting xmltodict (from wolframalpha==5.1.3->langflow)\n",
      "  Using cached xmltodict-0.14.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting more-itertools (from wolframalpha==5.1.3->langflow)\n",
      "  Using cached more_itertools-10.6.0-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting jaraco.context (from wolframalpha==5.1.3->langflow)\n",
      "  Using cached jaraco.context-6.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting multidict (from wolframalpha==5.1.3->langflow)\n",
      "  Using cached multidict-6.2.0-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting multitasking>=0.0.7 (from yfinance==0.2.50->langflow)\n",
      "  Using cached multitasking-0.0.11-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting frozendict>=2.3.4 (from yfinance==0.2.50->langflow)\n",
      "  Using cached frozendict-2.4.6-py312-none-any.whl.metadata (23 kB)\n",
      "Collecting peewee>=3.16.2 (from yfinance==0.2.50->langflow)\n",
      "  Using cached peewee-3.17.9.tar.gz (3.0 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting html5lib>=1.1 (from yfinance==0.2.50->langflow)\n",
      "  Using cached html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: zstandard in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from clickhouse-connect==0.7.19->langflow-base==0.2.0->langflow) (0.23.0)\n",
      "Collecting lz4 (from clickhouse-connect==0.7.19->langflow-base==0.2.0->langflow)\n",
      "  Using cached lz4-4.4.3-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.4.3->langchain-cohere==0.3.3->langflow)\n",
      "  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pyautogen==0.8.3 (from ag2>=0.1.0->langflow)\n",
      "  Using cached pyautogen-0.8.3-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting docker (from pyautogen==0.8.3->ag2>=0.1.0->langflow)\n",
      "  Using cached docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "INFO: pip is looking at multiple versions of pyautogen to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting ag2>=0.1.0 (from langflow)\n",
      "  Using cached ag2-0.8.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from httpx>=0.19.0->assemblyai==0.35.1->langflow) (1.0.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from httpx>=0.19.0->assemblyai==0.35.1->langflow) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.19.0->assemblyai==0.35.1->langflow) (0.14.0)\n",
      "Collecting pyautogen==0.8.2 (from ag2>=0.1.0->langflow)\n",
      "  Using cached pyautogen-0.8.2-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting ag2>=0.1.0 (from langflow)\n",
      "  Using cached ag2-0.8.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting pyautogen==0.8.1 (from ag2>=0.1.0->langflow)\n",
      "  Using cached pyautogen-0.8.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting fast-depends<3,>=2.4.12 (from pyautogen==0.8.1->ag2>=0.1.0->langflow)\n",
      "  Using cached fast_depends-2.4.12-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting ag2>=0.1.0 (from langflow)\n",
      "  Using cached ag2-0.8.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting pyautogen==0.8.0 (from ag2>=0.1.0->langflow)\n",
      "  Using cached pyautogen-0.8.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting ag2>=0.1.0 (from langflow)\n",
      "  Using cached ag2-0.7.6-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting pyautogen==0.7.6 (from ag2>=0.1.0->langflow)\n",
      "  Using cached pyautogen-0.7.6-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting ag2>=0.1.0 (from langflow)\n",
      "  Using cached ag2-0.7.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting pyautogen==0.7.5 (from ag2>=0.1.0->langflow)\n",
      "  Using cached pyautogen-0.7.5-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting termcolor (from pyautogen==0.7.5->ag2>=0.1.0->langflow)\n",
      "  Using cached termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting websockets>=11.0 (from assemblyai==0.35.1->langflow)\n",
      "  Using cached websockets-14.2-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
      "Collecting caio<0.10.0,>=0.9.0 (from aiofile<4.0.0,>=3.9.0->langflow)\n",
      "  Using cached caio-0.9.21.tar.gz (26 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting apify-shared>=1.1.2 (from apify-client>=1.8.1->langflow)\n",
      "  Using cached apify_shared-1.3.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting openinference-instrumentation>=0.1.21 (from arize-phoenix-otel>=0.6.1->langflow)\n",
      "  Using cached openinference_instrumentation-0.1.24-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting openinference-semantic-conventions>=0.1.9 (from arize-phoenix-otel>=0.6.1->langflow)\n",
      "  Using cached openinference_semantic_conventions-0.1.15-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting opentelemetry-exporter-otlp (from arize-phoenix-otel>=0.6.1->langflow)\n",
      "  Using cached opentelemetry_exporter_otlp-1.31.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-proto>=1.12.0 (from arize-phoenix-otel>=0.6.1->langflow)\n",
      "  Using cached opentelemetry_proto-1.31.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-semantic-conventions (from arize-phoenix-otel>=0.6.1->langflow)\n",
      "  Using cached opentelemetry_semantic_conventions-0.52b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting lsprotocol<2024.0.0,>=2023.0.1 (from astra-assistants~=2.2.9->astra-assistants[tools]~=2.2.9->langflow)\n",
      "  Using cached lsprotocol-2023.0.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting python-lsp-jsonrpc<2.0.0,>=1.1.2 (from astra-assistants~=2.2.9->astra-assistants[tools]~=2.2.9->langflow)\n",
      "  Using cached python_lsp_jsonrpc-1.1.2-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting ruff<9.0.0,>=0.6.2 (from astra-assistants~=2.2.9->astra-assistants[tools]~=2.2.9->langflow)\n",
      "  Using cached ruff-0.11.2-py3-none-win_amd64.whl.metadata (26 kB)\n",
      "Collecting tree-sitter<0.24.0,>=0.23.0 (from astra-assistants~=2.2.9->astra-assistants[tools]~=2.2.9->langflow)\n",
      "  Using cached tree_sitter-0.23.2-cp312-cp312-win_amd64.whl.metadata (10 kB)\n",
      "Collecting tree-sitter-python<0.24.0,>=0.23.0 (from astra-assistants~=2.2.9->astra-assistants[tools]~=2.2.9->langflow)\n",
      "  Using cached tree_sitter_python-0.23.6-cp39-abi3-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting e2b<2.0.0,>=1.0.1 (from astra-assistants[tools]~=2.2.9->langflow)\n",
      "  Using cached e2b-1.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting e2b-code-interpreter<2.0.0,>=1.0.1 (from astra-assistants[tools]~=2.2.9->langflow)\n",
      "  Using cached e2b_code_interpreter-1.1.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0.0,>=0.23.2->huggingface-hub[inference]<1.0.0,>=0.23.2->langflow)\n",
      "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-community~=0.3.10 (from langflow)\n",
      "  Using cached langchain_community-0.3.19-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Using cached langchain_community-0.3.18-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Using cached langchain_community-0.3.17-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Using cached langchain_community-0.3.16-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community~=0.3.10->langflow)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain-community~=0.3.10 (from langflow)\n",
      "  Using cached langchain_community-0.3.15-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.14-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.13-py3-none-any.whl.metadata (2.9 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached langchain_community-0.3.12-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.11-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached langchain_community-0.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "INFO: pip is looking at multiple versions of mcp to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting mcp>=0.9.1 (from langflow)\n",
      "  Using cached mcp-1.4.1-py3-none-any.whl.metadata (18 kB)\n",
      "  Using cached mcp-1.4.0-py3-none-any.whl.metadata (18 kB)\n",
      "  Using cached mcp-1.3.0-py3-none-any.whl.metadata (18 kB)\n",
      "  Using cached mcp-1.2.1-py3-none-any.whl.metadata (15 kB)\n",
      "  Using cached mcp-1.2.0-py3-none-any.whl.metadata (15 kB)\n",
      "  Using cached mcp-1.1.3-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting sse-starlette>=1.6.1 (from mcp>=0.9.1->langflow)\n",
      "  Using cached sse_starlette-2.2.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting starlette>=0.27 (from mcp>=0.9.1->langflow)\n",
      "  Using cached starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting opentelemetry-instrumentation (from openinference-instrumentation-langchain>=0.1.29->langflow)\n",
      "  Using cached opentelemetry_instrumentation-0.52b1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting pydantic-ai-slim==0.0.43 (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai>=0.0.19->langflow)\n",
      "  Using cached pydantic_ai_slim-0.0.43-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting eval-type-backport>=0.2.0 (from pydantic-ai-slim==0.0.43->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai>=0.0.19->langflow)\n",
      "  Using cached eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting griffe>=1.3.2 (from pydantic-ai-slim==0.0.43->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai>=0.0.19->langflow)\n",
      "  Using cached griffe-1.6.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting pydantic-graph==0.0.43 (from pydantic-ai-slim==0.0.43->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai>=0.0.19->langflow)\n",
      "  Using cached pydantic_graph-0.0.43-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic-ai-slim==0.0.43->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai>=0.0.19->langflow)\n",
      "  Using cached typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting argcomplete>=3.5.0 (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai>=0.0.19->langflow)\n",
      "  Using cached argcomplete-3.6.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting mistralai>=1.2.5 (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai>=0.0.19->langflow)\n",
      "  Using cached mistralai-1.6.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting logfire-api>=1.2.0 (from pydantic-graph==0.0.43->pydantic-ai-slim==0.0.43->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mcp,mistral,openai,vertexai]==0.0.43->pydantic-ai>=0.0.19->langflow)\n",
      "  Using cached logfire_api-3.9.0-py3-none-any.whl.metadata (971 bytes)\n",
      "INFO: pip is still looking at multiple versions of mcp to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting langflow\n",
      "  Using cached langflow-1.1.4.post1-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting composio-core==0.6.16 (from langflow)\n",
      "  Using cached composio_core-0.6.16-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting composio-langchain==0.6.16 (from langflow)\n",
      "  Using cached composio_langchain-0.6.16-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting crewai~=0.86.0 (from langflow)\n",
      "  Using cached crewai-0.86.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting langchain-nvidia-ai-endpoints==0.3.5 (from langflow)\n",
      "  Using cached langchain_nvidia_ai_endpoints-0.3.5-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting langflow-base==0.1.4.post1 (from langflow)\n",
      "  Using cached langflow_base-0.1.4.post1-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting litellm==1.59.8 (from langflow)\n",
      "  Using cached litellm-1.59.8-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting pyarrow==17.0.0 (from langflow)\n",
      "  Using cached pyarrow-17.0.0-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting pywin32<307,>=306 (from langflow)\n",
      "  Using cached pywin32-306-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting orjson==3.10.0 (from langflow-base==0.1.4.post1->langflow)\n",
      "  Using cached orjson-3.10.0-cp312-none-win_amd64.whl.metadata (50 kB)\n",
      "Collecting pandas==2.2.2 (from langflow-base==0.1.4.post1->langflow)\n",
      "  Using cached pandas-2.2.2-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting pillow<11.0.0,>=10.2.0 (from langflow-base==0.1.4.post1->langflow)\n",
      "  Using cached pillow-10.4.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "INFO: pip is still looking at multiple versions of pyautogen to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting crewai-tools>=0.17.0 (from crewai~=0.86.0->langflow)\n",
      "  Using cached crewai_tools-0.38.1-py3-none-any.whl.metadata (5.5 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting langflow\n",
      "  Using cached langflow-1.1.4-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting langflow-base==0.1.4 (from langflow)\n",
      "  Using cached langflow_base-0.1.4-py3-none-any.whl.metadata (5.5 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting langflow\n",
      "  Using cached langflow-1.1.3-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting langflow-base==0.1.3 (from langflow)\n",
      "  Using cached langflow_base-0.1.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting langflow\n",
      "  Using cached langflow-1.1.2-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting composio-core==0.6.13 (from langflow)\n",
      "  Using cached composio_core-0.6.13-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting composio-langchain==0.6.13 (from langflow)\n",
      "  Using cached composio_langchain-0.6.13-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting langflow-base==0.1.2 (from langflow)\n",
      "  Using cached langflow_base-0.1.2-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting litellm==1.54.1 (from langflow)\n",
      "  Using cached litellm-1.54.1-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting langflow\n",
      "  Using cached langflow-1.1.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting assemblyai<1.0.0,>=0.33.0 (from langflow)\n",
      "  Using cached assemblyai-0.37.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting atlassian-python-api<4.0.0,>=3.41.16 (from langflow)\n",
      "  Using cached atlassian_python_api-3.41.21-py3-none-any.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.2 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from langflow) (4.13.3)\n",
      "Collecting chromadb<1.0.0,>=0.4 (from langflow)\n",
      "  Using cached chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting composio-langchain==0.5.42 (from langflow)\n",
      "  Using cached composio_langchain-0.5.42-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting dspy-ai<3.0.0,>=2.4.0 (from langflow)\n",
      "  Using cached dspy_ai-2.6.14-py3-none-any.whl.metadata (286 bytes)\n",
      "Collecting duckduckgo-search<7.0.0,>=6.3.4 (from langflow)\n",
      "  Using cached duckduckgo_search-6.4.2-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting elasticsearch<9.0.0,>=8.12.0 (from langflow)\n",
      "  Using cached elasticsearch-8.17.2-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting faiss-cpu<2.0.0,>=1.8.0 (from langflow)\n",
      "  Using cached faiss_cpu-1.10.0-cp312-cp312-win_amd64.whl.metadata (4.5 kB)\n",
      "Collecting fastavro<2.0.0,>=1.8.0 (from langflow)\n",
      "  Using cached fastavro-1.10.0-cp312-cp312-win_amd64.whl.metadata (5.7 kB)\n",
      "Collecting gitpython<4.0.0,>=3.1.43 (from langflow)\n",
      "  Using cached GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting google-api-python-client<3.0.0,>=2.130.0 (from langflow)\n",
      "  Using cached google_api_python_client-2.165.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting json-repair<1.0.0,>=0.25.2 (from langflow)\n",
      "  Using cached json_repair-0.40.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting langchain-anthropic<1.0.0,>=0.1.23 (from langflow)\n",
      "  Using cached langchain_anthropic-0.3.10-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langchain-astradb~=0.5.2 (from langflow)\n",
      "  Using cached langchain_astradb-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting langchain-aws<1.0.0,>=0.1.16 (from langflow)\n",
      "  Using cached langchain_aws-0.2.17-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting langchain-chroma<1.0.0,>=0.1.1 (from langflow)\n",
      "  Using cached langchain_chroma-0.2.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting langchain-cohere<1.0.0,>=0.1.5 (from langflow)\n",
      "  Using cached langchain_cohere-0.4.3-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting langchain-elasticsearch<1.0.0,>=0.2.0 (from langflow)\n",
      "  Using cached langchain_elasticsearch-0.3.2-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting langchain-google-community~=2.0.1 (from langflow)\n",
      "  Using cached langchain_google_community-2.0.7-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting langchain-google-genai<3.0.0,>=2.0.1 (from langflow)\n",
      "  Using cached langchain_google_genai-2.1.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting langchain-google-vertexai~=2.0.5 (from langflow)\n",
      "  Using cached langchain_google_vertexai-2.0.16-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting langchain-groq<1.0.0,>=0.1.9 (from langflow)\n",
      "  Using cached langchain_groq-0.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting langchain-milvus<1.0.0,>=0.1.1 (from langflow)\n",
      "  Using cached langchain_milvus-0.1.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langchain-mistralai~=0.2.0 (from langflow)\n",
      "  Using cached langchain_mistralai-0.2.9-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting langchain-mongodb<1.0.0,>=0.1.6 (from langflow)\n",
      "  Using cached langchain_mongodb-0.5.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting langchain-nvidia-ai-endpoints~=0.3.0 (from langflow)\n",
      "  Using cached langchain_nvidia_ai_endpoints-0.3.9-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting langchain-ollama<1.0.0,>=0.2.0 (from langflow)\n",
      "  Using cached langchain_ollama-0.3.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting langchain-openai~=0.2.2 (from langflow)\n",
      "  Using cached langchain_openai-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting langchain-pinecone<1.0.0,>=0.1.3 (from langflow)\n",
      "  Using cached langchain_pinecone-0.2.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting langchain-unstructured~=0.1.5 (from langflow)\n",
      "  Using cached langchain_unstructured-0.1.6-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: langchain~=0.3.3 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from langflow) (0.3.21)\n",
      "Collecting langflow-base==0.1.1 (from langflow)\n",
      "  Using cached langflow_base-0.1.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting litellm<2.0.0,>=1.44.0 (from langflow)\n",
      "  Using cached litellm-1.63.14-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting mem0ai<1.0.0,>=0.1.26 (from langflow)\n",
      "  Using cached mem0ai-0.1.74-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting pgvector<1.0.0,>=0.2.3 (from langflow)\n",
      "  Using cached pgvector-0.4.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting pymongo<5.0.0,>=4.6.0 (from langflow)\n",
      "  Using cached pymongo-4.11.3-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "Collecting spider-client<1.0.0,>=0.0.27 (from langflow)\n",
      "  Using cached spider-client-0.1.28.tar.gz (15 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting upstash-vector<1.0.0,>=0.5.0 (from langflow)\n",
      "  Using cached upstash_vector-0.8.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting weaviate-client<5.0.0,>=4.8 (from langflow)\n",
      "  Using cached weaviate_client-4.11.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting yfinance<1.0.0,>=0.2.40 (from langflow)\n",
      "  Using cached yfinance-0.2.55-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting composio-core<=0.5.42,>=0.5.40 (from composio-langchain==0.5.42->langflow)\n",
      "  Using cached composio_core-0.5.42-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting crewai~=0.80.0 (from langflow-base==0.1.1->langflow)\n",
      "  Using cached crewai-0.80.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting pydantic>=2.6.4 (from composio-langchain==0.5.42->langflow)\n",
      "  Using cached pydantic-2.7.4-py3-none-any.whl.metadata (109 kB)\n",
      "Collecting sqlmodel==0.0.18 (from langflow-base==0.1.1->langflow)\n",
      "  Using cached sqlmodel-0.0.18-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb<1.0.0,>=0.4->langflow)\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from cohere<6.0,>=5.5.6->langchain-cohere==0.3.3->langflow) (2.27.2)\n",
      "INFO: pip is looking at multiple versions of langchain-aws to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-aws<1.0.0,>=0.1.16 (from langflow)\n",
      "  Using cached langchain_aws-0.2.16-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Using cached langchain_aws-0.2.15-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Using cached langchain_aws-0.2.14-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Using cached langchain_aws-0.2.13-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Using cached langchain_aws-0.2.12-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Using cached langchain_aws-0.2.11-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Using cached langchain_aws-0.2.10-py3-none-any.whl.metadata (3.2 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-aws to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached langchain_aws-0.2.9-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting types-pyyaml<7.0.0.0,>=6.0.12.20240917 (from langchain-cohere<1.0.0,>=0.1.5->langflow)\n",
      "  Using cached types_PyYAML-6.0.12.20241230-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting google-ai-generativelanguage<0.7.0,>=0.6.16 (from langchain-google-genai<3.0.0,>=2.0.1->langflow)\n",
      "  Using cached google_ai_generativelanguage-0.6.17-py3-none-any.whl.metadata (9.8 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-google-vertexai to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-google-vertexai~=2.0.5 (from langflow)\n",
      "  Using cached langchain_google_vertexai-2.0.15-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached langchain_google_vertexai-2.0.14-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached langchain_google_vertexai-2.0.13-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached langchain_google_vertexai-2.0.12-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached langchain_google_vertexai-2.0.11-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached langchain_google_vertexai-2.0.10-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached langchain_google_vertexai-2.0.9-py3-none-any.whl.metadata (3.8 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-google-vertexai to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached langchain_google_vertexai-2.0.8-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb<1.0.0,>=0.4->langflow)\n",
      "  Using cached onnxruntime-1.19.2-cp312-cp312-win_amd64.whl.metadata (4.7 kB)\n",
      "Collecting unstructured-client<1,>=0.27.0 (from langchain-unstructured~=0.1.5->langflow)\n",
      "  Using cached unstructured_client-0.31.3-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting azure-search-documents<12.0.0,>=11.5.0 (from mem0ai<1.0.0,>=0.1.26->langflow)\n",
      "  Using cached azure_search_documents-11.5.2-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting psycopg2-binary<3.0.0,>=2.9.10 (from mem0ai<1.0.0,>=0.1.26->langflow)\n",
      "  Using cached psycopg2_binary-2.9.10-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting psycopg>=3.0.7 (from psycopg[binary]>=3.0.7; extra == \"postgresql-psycopgbinary\"->sqlalchemy[aiosqlite,postgresql-psycopg2binary,postgresql-psycopgbinary]<3.0.0,>=2.0.38->langflow)\n",
      "  Using cached psycopg-3.2.6-py3-none-any.whl.metadata (4.4 kB)\n",
      "INFO: pip is looking at multiple versions of weaviate-client to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting weaviate-client<5.0.0,>=4.8 (from langflow)\n",
      "  Using cached weaviate_client-4.11.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached weaviate_client-4.11.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached weaviate_client-4.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached weaviate_client-4.10.3-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached weaviate_client-4.10.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached weaviate_client-4.10.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting httpx<1.0.0,>=0.27 (from httpx[http2]<1.0.0,>=0.27->langflow-base==0.1.1->langflow)\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "INFO: pip is still looking at multiple versions of weaviate-client to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting weaviate-client<5.0.0,>=4.8 (from langflow)\n",
      "  Using cached weaviate_client-4.9.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->composio-core==0.7.1->langflow)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->composio-core==0.7.1->langflow)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from aiohttp->composio-core==0.7.1->langflow) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->composio-core==0.7.1->langflow)\n",
      "  Using cached frozenlist-1.5.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp->composio-core==0.7.1->langflow)\n",
      "  Using cached yarl-1.18.3-cp312-cp312-win_amd64.whl.metadata (71 kB)\n",
      "Collecting Mako (from alembic<2.0.0,>=1.13.0->langflow-base==0.2.0->langflow)\n",
      "  Using cached Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting distro<2,>=1.7.0 (from anthropic<1,>=0.39.0->langchain-anthropic==0.3.0->langflow)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from anthropic<1,>=0.39.0->langchain-anthropic==0.3.0->langflow)\n",
      "  Using cached jiter-0.9.0-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting deprecation<2.2.0,>=2.1.0 (from astrapy<2.0.0,>=1.5.2->langchain-astradb==0.5.2->langflow)\n",
      "  Using cached deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting toml<0.11.0,>=0.10.2 (from astrapy<2.0.0,>=1.5.2->langchain-astradb==0.5.2->langflow)\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting uuid6>=2024.1.12 (from astrapy<2.0.0,>=1.5.2->langchain-astradb==0.5.2->langflow)\n",
      "  Using cached uuid6-2024.7.10-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting azure-core>=1.28.0 (from azure-search-documents<12.0.0,>=11.5.0->mem0ai<1.0.0,>=0.1.26->langflow)\n",
      "  Using cached azure_core-1.32.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting azure-common>=1.1 (from azure-search-documents<12.0.0,>=11.5.0->mem0ai<1.0.0,>=0.1.26->langflow)\n",
      "  Using cached azure_common-1.1.28-py2.py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting isodate>=0.6.0 (from azure-search-documents<12.0.0,>=11.5.0->mem0ai<1.0.0,>=0.1.26->langflow)\n",
      "  Using cached isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pycryptodome>=3.8.0 (from bce-python-sdk>=0.8.79->qianfan==0.3.5->langflow)\n",
      "  Using cached pycryptodome-3.22.0-cp37-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting future>=0.6.0 (from bce-python-sdk>=0.8.79->qianfan==0.3.5->langflow)\n",
      "  Using cached future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb==0.5.23->langflow)\n",
      "  Using cached pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb==0.5.23->langflow) (0.4.6)\n",
      "Collecting cassandra-driver<4.0.0,>=3.28.0 (from cassio<0.2.0,>=0.1.7->ragstack-ai-knowledge-store==0.2.1->langflow)\n",
      "  Using cached cassandra_driver-3.29.2-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from cryptography<44.0.0,>=42.0.5->langflow-base==0.2.0->langflow) (1.17.1)\n",
      "INFO: pip is looking at multiple versions of dspy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting dspy>=2.6.5 (from dspy-ai<3.0.0,>=2.4.0->langflow)\n",
      "  Using cached dspy-2.6.13-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting ujson (from dspy>=2.6.5->dspy-ai<3.0.0,>=2.4.0->langflow)\n",
      "  Using cached ujson-5.10.0-cp312-cp312-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting datasets>=2.14.6 (from dspy>=2.6.5->dspy-ai<3.0.0,>=2.4.0->langflow)\n",
      "  Using cached datasets-3.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting optuna (from dspy>=2.6.5->dspy-ai<3.0.0,>=2.4.0->langflow)\n",
      "  Using cached optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting magicattr~=0.1.6 (from dspy>=2.6.5->dspy-ai<3.0.0,>=2.4.0->langflow)\n",
      "  Using cached magicattr-0.1.6-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting cloudpickle (from dspy>=2.6.5->dspy-ai<3.0.0,>=2.4.0->langflow)\n",
      "  Using cached cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting protobuf>=4.25.0 (from langchain-google-calendar-tools==0.0.1->langflow)\n",
      "  Using cached protobuf-5.29.4-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting simsimd>=3 (from elasticsearch[vectorstore-mmr]<9.0.0,>=8.13.1->langchain-elasticsearch<1.0.0,>=0.2.0->langflow)\n",
      "  Using cached simsimd-6.2.1-cp312-cp312-win_amd64.whl.metadata (67 kB)\n",
      "INFO: pip is looking at multiple versions of firecrawl-py to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting firecrawl-py<2.0.0,>=1.0.16 (from langflow-base==0.1.1->langflow)\n",
      "  Using cached firecrawl_py-1.14.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached firecrawl_py-1.13.5-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached firecrawl_py-1.13.4-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached firecrawl_py-1.13.3-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached firecrawl_py-1.13.2-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached firecrawl_py-1.13.1-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached firecrawl_py-1.13.0-py3-none-any.whl.metadata (10 kB)\n",
      "INFO: pip is still looking at multiple versions of firecrawl-py to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached firecrawl_py-1.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached firecrawl_py-1.11.1-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached firecrawl_py-1.11.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached firecrawl_py-1.10.2-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached firecrawl_py-1.10.1-py3-none-any.whl.metadata (10 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached firecrawl_py-1.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached firecrawl_py-1.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached firecrawl_py-1.8.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached firecrawl_py-1.7.1-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached firecrawl_py-1.7.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached firecrawl_py-1.6.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython==3.1.43->langflow)\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai<3.0.0,>=2.0.1->langflow)\n",
      "  Using cached proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client==2.154.0->langflow)\n",
      "  Using cached googleapis_common_protos-1.69.2-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client==2.154.0->langflow)\n",
      "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client==2.154.0->langflow)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 (from google-cloud-aiplatform<2.0.0,>=1.70.0->langchain-google-vertexai==2.0.7->langflow)\n",
      "  Using cached google_cloud_bigquery-3.30.0-py2.py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting google-cloud-resource-manager<3.0.0,>=1.3.3 (from google-cloud-aiplatform<2.0.0,>=1.70.0->langchain-google-vertexai==2.0.7->langflow)\n",
      "  Using cached google_cloud_resource_manager-1.14.2-py3-none-any.whl.metadata (9.6 kB)\n",
      "Collecting shapely<3.0.0 (from google-cloud-aiplatform<2.0.0,>=1.70.0->langchain-google-vertexai==2.0.7->langflow)\n",
      "  Using cached shapely-2.0.7-cp312-cp312-win_amd64.whl.metadata (7.1 kB)\n",
      "Collecting google-resumable-media>=2.7.2 (from google-cloud-storage<3.0.0,>=2.18.0->langchain-google-vertexai==2.0.7->langflow)\n",
      "  Using cached google_resumable_media-2.7.2-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage<3.0.0,>=2.18.0->langchain-google-vertexai==2.0.7->langflow)\n",
      "  Using cached google_crc32c-1.7.0-cp312-cp312-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting pyparsing (from grandalf<1.0.0,>=0.8.0->langflow-base==0.2.0->langflow)\n",
      "  Using cached pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting h2<5,>=3 (from httpx[http2]<1.0.0,>=0.27->langflow-base==0.1.1->langflow)\n",
      "  Using cached h2-4.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata>=4.8.1->composio-core==0.7.1->langflow)\n",
      "  Using cached zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from jsonschema<5,>=4.21.1->composio-core==0.7.1->langflow) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from jsonschema<5,>=4.21.1->composio-core==0.7.1->langflow) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from jsonschema<5,>=4.21.1->composio-core==0.7.1->langflow) (0.23.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\praga\\ai_agents_bootcamp\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.22->langchain==0.3.10->langflow) (1.33)\n",
      "Collecting pytest<9,>=7 (from langchain-tests<0.4.0,>=0.3.7->langchain-pinecone==0.2.2->langflow)\n",
      "  Using cached pytest-8.3.5-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting pytest-asyncio<1,>=0.20 (from langchain-tests<0.4.0,>=0.3.7->langchain-pinecone==0.2.2->langflow)\n",
      "  Using cached pytest_asyncio-0.25.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting syrupy<5,>=4 (from langchain-tests<0.4.0,>=0.3.7->langchain-pinecone==0.2.2->langflow)\n",
      "  Using cached syrupy-4.9.0-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting pytest-socket<1,>=0.6.0 (from langchain-tests<0.4.0,>=0.3.7->langchain-pinecone==0.2.2->langflow)\n",
      "  Using cached pytest_socket-0.7.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting win32-setctime>=1.0.0 (from loguru<1.0.0,>=0.7.1->langflow-base==0.2.0->langflow)\n",
      "  Using cached win32_setctime-1.2.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting cattrs!=23.2.1 (from lsprotocol<2024.0.0,>=2023.0.1->astra-assistants~=2.2.9->astra-assistants[tools]~=2.2.9->langflow)\n",
      "  Using cached cattrs-24.1.2-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting dill>=0.3.9 (from multiprocess<1.0.0,>=0.70.14->langflow-base==0.2.0->langflow)\n",
      "  Using cached dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
      "INFO: pip is looking at multiple versions of ollama to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting ollama<1,>=0.4.4 (from langchain-ollama<1.0.0,>=0.2.0->langflow)\n",
      "  Using cached ollama-0.4.6-py3-none-any.whl.metadata (4.7 kB)\n",
      "  Using cached ollama-0.4.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "  Using cached ollama-0.4.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.7 (from langchain~=0.3.3->langflow)\n",
      "  Using cached langchain_text_splitters-0.3.7-py3-none-any.whl.metadata (1.9 kB)\n",
      "INFO: pip is still looking at multiple versions of ollama to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-tests<1.0.0,>=0.3.7 (from langchain-pinecone<1.0.0,>=0.1.3->langflow)\n",
      "  Using cached langchain_tests-0.3.14-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting langchain-experimental<1.0.0,>=0.0.61 (from langflow-base==0.1.1->langflow)\n",
      "  Using cached langchain_experimental-0.3.3-py3-none-any.whl.metadata (1.7 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting langchain-core~=0.3.15 (from langflow-base==0.1.1->langflow)\n",
      "  Using cached langchain_core-0.3.47-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting groq<1,>=0.4.1 (from langchain-groq<1.0.0,>=0.1.9->langflow)\n",
      "  Using cached groq-0.19.0-py3-none-any.whl.metadata (15 kB)\n",
      "  Using cached groq-0.18.0-py3-none-any.whl.metadata (14 kB)\n",
      "  Using cached groq-0.17.0-py3-none-any.whl.metadata (14 kB)\n",
      "  Using cached groq-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "  Using cached groq-0.15.0-py3-none-any.whl.metadata (14 kB)\n",
      "  Using cached groq-0.14.0-py3-none-any.whl.metadata (14 kB)\n",
      "  Using cached groq-0.13.1-py3-none-any.whl.metadata (14 kB)\n",
      "  Using cached groq-0.13.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached groq-0.12.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached groq-0.11.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached groq-0.10.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached groq-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached groq-0.8.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached groq-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached groq-0.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached groq-0.5.0-py3-none-any.whl.metadata (12 kB)\n",
      "  Using cached groq-0.4.2-py3-none-any.whl.metadata (12 kB)\n",
      "  Using cached groq-0.4.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting gotrue<3.0,>=1.3 (from supabase==2.6.0->langflow)\n",
      "  Using cached gotrue-2.11.3-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.11.2-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.11.1-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.11.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.10.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.9.3-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.9.2-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.9.1-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.9.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.8.1-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.8.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.7.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.6.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "  Using cached gotrue-2.6.1-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.6.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.5.5-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.5.4-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.5.3-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.5.2-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.5.1-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.5.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.4.4-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.4.3-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached gotrue-2.4.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "  Using cached gotrue-2.4.1-py3-none-any.whl.metadata (6.0 kB)\n",
      "INFO: pip is looking at multiple versions of gotrue to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached gotrue-2.1.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached gotrue-2.0.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached gotrue-1.3.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached gotrue-1.3.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting e2b-code-interpreter<2.0.0,>=1.0.1 (from astra-assistants[tools]~=2.2.9->langflow)\n",
      "  Using cached e2b_code_interpreter-1.1.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting google-cloud-aiplatform<2.0.0,>=1.70.0 (from langchain-google-vertexai==2.0.7->langflow)\n",
      "  Using cached google_cloud_aiplatform-1.84.0-py2.py3-none-any.whl.metadata (33 kB)\n",
      "Collecting shapely<3.0.0dev (from google-cloud-aiplatform<2.0.0,>=1.70.0->langchain-google-vertexai==2.0.7->langflow)\n",
      "  Using cached shapely-2.1.0rc1-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
      "Collecting google-cloud-aiplatform<2.0.0,>=1.70.0 (from langchain-google-vertexai==2.0.7->langflow)\n",
      "  Using cached google_cloud_aiplatform-1.83.0-py2.py3-none-any.whl.metadata (33 kB)\n",
      "  Using cached google_cloud_aiplatform-1.82.0-py2.py3-none-any.whl.metadata (33 kB)\n",
      "  Using cached google_cloud_aiplatform-1.81.0-py2.py3-none-any.whl.metadata (32 kB)\n",
      "  Using cached google_cloud_aiplatform-1.80.0-py2.py3-none-any.whl.metadata (32 kB)\n",
      "  Using cached google_cloud_aiplatform-1.79.0-py2.py3-none-any.whl.metadata (32 kB)\n",
      "  Using cached google_cloud_aiplatform-1.78.0-py2.py3-none-any.whl.metadata (31 kB)\n",
      "  Using cached google_cloud_aiplatform-1.77.0-py2.py3-none-any.whl.metadata (31 kB)\n",
      "  Using cached google_cloud_aiplatform-1.76.0-py2.py3-none-any.whl.metadata (31 kB)\n",
      "  Using cached google_cloud_aiplatform-1.75.0-py2.py3-none-any.whl.metadata (31 kB)\n",
      "  Using cached google_cloud_aiplatform-1.74.0-py2.py3-none-any.whl.metadata (31 kB)\n",
      "  Using cached google_cloud_aiplatform-1.73.0-py2.py3-none-any.whl.metadata (31 kB)\n",
      "  Using cached google_cloud_aiplatform-1.72.0-py2.py3-none-any.whl.metadata (31 kB)\n",
      "  Using cached google_cloud_aiplatform-1.71.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "  Using cached google_cloud_aiplatform-1.71.0-py2.py3-none-any.whl.metadata (32 kB)\n",
      "  Using cached google_cloud_aiplatform-1.70.0-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting fastapi-pagination<1.0.0,>=0.12.29 (from langflow-base==0.1.1->langflow)\n",
      "  Using cached fastapi_pagination-0.12.33-py3-none-any.whl.metadata (6.4 kB)\n",
      "  Using cached fastapi_pagination-0.12.32-py3-none-any.whl.metadata (6.3 kB)\n",
      "  Using cached fastapi_pagination-0.12.31-py3-none-any.whl.metadata (6.3 kB)\n",
      "  Using cached fastapi_pagination-0.12.30-py3-none-any.whl.metadata (6.3 kB)\n",
      "  Using cached fastapi_pagination-0.12.29-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting fastapi<1.0.0,>=0.115.2 (from langflow-base==0.1.1->langflow)\n",
      "  Using cached fastapi-0.115.10-py3-none-any.whl.metadata (27 kB)\n",
      "  Using cached fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting starlette<0.46.0,>=0.40.0 (from fastapi<1.0.0,>=0.115.2->langflow-base==0.1.1->langflow)\n",
      "  Using cached starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting fastapi<1.0.0,>=0.115.2 (from langflow-base==0.1.1->langflow)\n",
      "  Using cached fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
      "  Using cached fastapi-0.115.7-py3-none-any.whl.metadata (27 kB)\n",
      "  Using cached fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting starlette<0.42.0,>=0.40.0 (from fastapi<1.0.0,>=0.115.2->langflow-base==0.1.1->langflow)\n",
      "  Using cached starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting fastapi<1.0.0,>=0.115.2 (from langflow-base==0.1.1->langflow)\n",
      "  Using cached fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n",
      "  Using cached fastapi-0.115.4-py3-none-any.whl.metadata (27 kB)\n",
      "  Using cached fastapi-0.115.3-py3-none-any.whl.metadata (27 kB)\n",
      "  Using cached fastapi-0.115.2-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting starlette<0.41.0,>=0.37.2 (from fastapi<1.0.0,>=0.115.2->langflow-base==0.1.1->langflow)\n",
      "  Using cached starlette-0.40.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "INFO: pip is still looking at multiple versions of gotrue to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting e2b-code-interpreter<2.0.0,>=1.0.1 (from astra-assistants[tools]~=2.2.9->langflow)\n",
      "  Using cached e2b_code_interpreter-1.0.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\praga\\AI_Agents_Bootcamp\\.venv\\Lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 106, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\praga\\AI_Agents_Bootcamp\\.venv\\Lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 97, in _inner_run\n",
      "    return self.run(options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\praga\\AI_Agents_Bootcamp\\.venv\\Lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\praga\\AI_Agents_Bootcamp\\.venv\\Lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 386, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "                      ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\praga\\AI_Agents_Bootcamp\\.venv\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 95, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "                            ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\praga\\AI_Agents_Bootcamp\\.venv\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 546, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\praga\\AI_Agents_Bootcamp\\.venv\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 457, in resolve\n",
      "    raise ResolutionTooDeep(max_rounds)\n",
      "pip._vendor.resolvelib.resolvers.ResolutionTooDeep: 200000\n"
     ]
    }
   ],
   "source": [
    "%pip install langflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56594b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092cbba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac259d2a",
   "metadata": {},
   "source": [
    "### 🔐 Step 4: Install python-dotenv and create `.env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864dc229",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%pip install python-dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c995f4",
   "metadata": {},
   "source": [
    "\n",
    "Now create a file named `.env` in your **project root folder** (not inside the notebook folder).  \n",
    "Paste this inside the `.env` file:\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=sk-XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "```\n",
    "\n",
    "✅ Replace the placeholder with your actual API key from [https://platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys)\n",
    "\n",
    "Never share this key publicly!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8557d4",
   "metadata": {},
   "source": [
    "### ✅ Step 5: Load the OpenAI API Key from `.env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe622906",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(\"API Key Loaded:\", \"Yes\" if openai_api_key else \"No\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
