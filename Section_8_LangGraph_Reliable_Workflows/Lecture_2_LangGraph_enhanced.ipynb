{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4f0388b5",
      "metadata": {},
      "source": [
        "\n",
        "# Section 8, Lecture 2: Hands-on LangGraph: Build a Reliable AI Workflow for Business\n",
        "\n",
        "Welcome to Lecture 2 of Section 8! In the last lecture, we introduced LangGraph and saw how it can help you build reliable AI workflows. Now, we\u2019re getting hands-on. In this notebook, you\u2019ll create your own LangGraph workflow to automate a real-world business task: triaging customer support inquiries. By the end, you\u2019ll have a working system that ensures reliability, saves time, and keeps your customers happy.\n",
        "\n",
        "### What You\u2019ll Build\n",
        "- A LangGraph workflow with three nodes:\n",
        "  - **Classify Node**: Determines the inquiry type (e.g., question, complaint, urgent).\n",
        "  - **Route Node**: Decides where to send the inquiry (AI agent or human).\n",
        "  - **Respond Node**: Sends an AI response or flags for human review.\n",
        "- The workflow will include error handling (e.g., retries) to ensure reliability.\n",
        "\n",
        "### Why This Matters for Business\n",
        "Triaging customer support inquiries manually takes hours and risks delays. With LangGraph, you\u2019ll automate this process with reliability, ensuring faster responses, fewer errors, and a better customer experience.\n",
        "\n",
        "Let\u2019s get started!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "beb99450",
      "metadata": {},
      "source": [
        "## \u2699\ufe0f Step 1: Installing LangGraph\n",
        "\n",
        "Before we build anything, we need to make sure LangGraph is installed and ready to go.\n",
        "\n",
        "### \ud83d\udce6 What We're Doing:\n",
        "- Verifying whether the LangGraph package is installed in your environment.\n",
        "- If not installed, you\u2019ll need to install it manually using:\n",
        "  ```bash\n",
        "  uv pip install langgraph\n",
        "  ```\n",
        "\n",
        "### \ud83d\udcbc Why This Matters:\n",
        "LangGraph is the backbone of your workflow automation\u2014just like a project management system ensures every step gets done reliably.\n",
        "\n",
        "### \ud83d\udee0\ufe0f Pro Tip:\n",
        "If you're not seeing a version output, double-check that your virtual environment is active and that you ran the install command in the terminal.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09499a2f",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# If you haven\u2019t installed LangGraph yet, run this in your terminal (not here):\n",
        "# uv pip install langgraph\n",
        "# Make sure your virtual environment is activated:\n",
        "# Mac/Linux: source .venv/bin/activate\n",
        "# Windows: .venv\\Scripts\\Activate\n",
        "\n",
        "# Verify the installation\n",
        "try:\n",
        "    import langgraph\n",
        "    print(\"LangGraph is installed! Version:\", langgraph.__version__)\n",
        "except ImportError:\n",
        "    print(\"LangGraph not found. Please install it using the command above.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e777488",
      "metadata": {},
      "source": [
        "## \ud83d\udd10 Step 2: Load Your OpenAI API Key\n",
        "\n",
        "To run intelligent workflows, we need GPT-4 to power decision-making. We\u2019ll access it securely using your OpenAI API key.\n",
        "\n",
        "### \ud83e\udde9 What We're Doing:\n",
        "- Loading the `.env` file that stores your API credentials.\n",
        "- Verifying that the key is accessible within the notebook.\n",
        "\n",
        "### \ud83d\udcbc Why This Matters:\n",
        "Securely storing and loading your API keys is a **best practice in real-world production systems**, where leaking keys can have cost and security implications.\n",
        "\n",
        "### \ud83d\udee0\ufe0f Pro Tip:\n",
        "Your `.env` file should contain a line like this:\n",
        "`OPENAI_API_KEY=your-key-here`\n",
        "Never hardcode it directly into your script or notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bde3b86b",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Load the .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Get the API key\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Verify the key\n",
        "if openai_api_key:\n",
        "    print(\"API key loaded successfully!\")\n",
        "else:\n",
        "    print(\"API key not found. Make sure your .env file has OPENAI_API_KEY set.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "166f2f56",
      "metadata": {},
      "source": [
        "## \ud83e\udde0 Step 3: Setting Up the LangGraph Workflow\n",
        "\n",
        "Let\u2019s lay the foundation for your AI-powered customer support triage system by creating a LangGraph workflow.\n",
        "\n",
        "### \ud83e\udde9 What We're Doing:\n",
        "- Creating a `StateGraph`, which lets us define and manage each step in the workflow.\n",
        "- Initializing the GPT-4 model as our language reasoning engine.\n",
        "- Creating a `WorkflowState` schema to store state across steps.\n",
        "\n",
        "### \ud83d\udcbc Why This Matters:\n",
        "In real business systems, each process must reliably move from one stage to another. LangGraph\u2019s StateGraph ensures your flow is consistent and recoverable.\n",
        "\n",
        "### \ud83d\udcca Real-World Use Case:\n",
        "Think of this like an automated ticket system\u2014once set up, it guarantees tickets are never lost or stuck.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "060f18fd",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_openai import ChatOpenAI\n",
        "from typing import Dict, Any\n",
        "\n",
        "# Initialize the LLM (GPT-4)\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4\",\n",
        "    api_key=openai_api_key\n",
        ")\n",
        "\n",
        "# Define the state to track the workflow\n",
        "class WorkflowState(dict):\n",
        "    inquiry: str\n",
        "    inquiry_type: str\n",
        "    response: str\n",
        "    needs_human: bool\n",
        "\n",
        "# Create the workflow graph\n",
        "workflow = StateGraph(WorkflowState)\n",
        "\n",
        "print(\"Workflow set up successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d275de6",
      "metadata": {},
      "source": [
        "## \ud83d\udd04 Step 4: Defining Nodes and Workflow Logic\n",
        "\n",
        "This is where your automation logic comes to life. Each **node** represents a step in the decision-making process.\n",
        "\n",
        "### \ud83e\udd16 Node Roles:\n",
        "- **Classify Node**: Uses GPT-4 to label the inquiry.\n",
        "- **Route Node**: Decides whether to escalate or respond.\n",
        "- **Respond Node**: Drafts a reply or flags for human review.\n",
        "\n",
        "### \ud83d\udd01 Flow Control:\n",
        "We connect nodes with **edges**, like arrows in a flowchart, that define how information flows from one step to another.\n",
        "\n",
        "### \ud83e\udde9 Why It Matters:\n",
        "This level of structure is critical in systems where mistakes are costly\u2014like customer complaints or legal queries. LangGraph ensures reliable, recoverable execution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "765e81a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Node 1: Classify the inquiry\n",
        "def classify_inquiry(state: WorkflowState) -> WorkflowState:\n",
        "    inquiry = state[\"inquiry\"]\n",
        "    prompt = f\"Classify this customer inquiry as a question, complaint, or urgent issue: {inquiry}\"\n",
        "    response = llm.invoke(prompt).content\n",
        "    state[\"inquiry_type\"] = response.lower()\n",
        "    return state\n",
        "\n",
        "# Node 2: Route the inquiry\n",
        "def route_inquiry(state: WorkflowState) -> WorkflowState:\n",
        "    inquiry_type = state[\"inquiry_type\"]\n",
        "    state[\"needs_human\"] = \"complaint\" in inquiry_type or \"urgent\" in inquiry_type\n",
        "    return state\n",
        "\n",
        "# Node 3: Respond or escalate\n",
        "def respond_or_escalate(state: WorkflowState) -> WorkflowState:\n",
        "    if state[\"needs_human\"]:\n",
        "        state[\"response\"] = \"Flagged for human review.\"\n",
        "    else:\n",
        "        prompt = f\"Draft a brief response to this customer inquiry: {state['inquiry']}\"\n",
        "        state[\"response\"] = llm.invoke(prompt).content\n",
        "    return state\n",
        "\n",
        "# Add nodes to the workflow\n",
        "workflow.add_node(\"classify\", classify_inquiry)\n",
        "workflow.add_node(\"route\", route_inquiry)\n",
        "workflow.add_node(\"respond\", respond_or_escalate)\n",
        "\n",
        "# Define edges (flow between nodes)\n",
        "workflow.set_entry_point(\"classify\")\n",
        "workflow.add_edge(\"classify\", \"route\")\n",
        "workflow.add_edge(\"route\", \"respond\")\n",
        "workflow.add_edge(\"respond\", END)\n",
        "\n",
        "# Compile the workflow\n",
        "app = workflow.compile()\n",
        "\n",
        "print(\"Nodes and edges defined successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f5ac193",
      "metadata": {},
      "source": [
        "## \ud83d\ude80 Step 5: Running the Workflow\n",
        "\n",
        "Now let\u2019s run your LangGraph pipeline on a **real-world inquiry**: \u201cMy order is delayed\u2014what\u2019s going on?\u201d\n",
        "\n",
        "### \ud83e\uddea What Happens:\n",
        "1. The inquiry is classified (e.g., as a complaint).\n",
        "2. The system routes it to either an agent or flags it.\n",
        "3. A response is generated or it's escalated to a human.\n",
        "\n",
        "### \ud83d\udcbc Why This Matters:\n",
        "You just built a reliable triage bot\u2014imagine deploying this inside Zendesk or Freshdesk. It ensures **zero tickets fall through the cracks**.\n",
        "\n",
        "### \u270f\ufe0f Try This:\n",
        "Replace the sample inquiry with something like \u201cI want to cancel my subscription\u201d and see how the flow adapts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93e89c9b",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "initial_state = WorkflowState(\n",
        "    inquiry=\"My order is delayed\u2014what\u2019s going on?\",\n",
        "    inquiry_type=\"\",\n",
        "    response=\"\",\n",
        "    needs_human=False\n",
        ")\n",
        "\n",
        "result = app.invoke(initial_state)\n",
        "\n",
        "# Print the final output\n",
        "print(\"Final Output:\\n\", result[\"response\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fbe7806",
      "metadata": {},
      "source": [
        "## \ud83c\udf93 Wrap-Up and What\u2019s Next\n",
        "\n",
        "Congratulations! You\u2019ve just built your **first reliable AI workflow using LangGraph**.\n",
        "\n",
        "### \ud83d\udca1 What You Built:\n",
        "- A structured graph with intelligent steps (nodes).\n",
        "- A decision-making pipeline with GPT-4.\n",
        "- A workflow that can **scale, retry, and never miss a beat**.\n",
        "\n",
        "### \ud83e\udde0 Reflect:\n",
        "- How could this apply in your business?\n",
        "- Could you use a similar flow for onboarding, refunds, or lead scoring?\n",
        "\n",
        "### \ud83d\udc49 Next:\n",
        "In the next lecture, we\u2019ll enhance this with **memory and branching logic**, enabling smarter decisions based on past interactions.\n"
      ]
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}