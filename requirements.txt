# AI Agents Bootcamp - Compatible Requirements
# Compatible with your existing langflow==1.2.0 and langchain==0.3.10

# =============================================================================
# YOUR EXISTING CORE (KEEPING THESE EXACT VERSIONS)
# =============================================================================
langflow==1.2.0                  # Your existing Langflow version
langchain==0.3.10                # Your existing LangChain version  
openai==1.68.2                   # Your existing OpenAI version
jupyter==1.1.1                   # Your existing Jupyter version
python-dotenv==1.0.1             # Your existing dotenv version
ipykernel==6.29.5                # Your existing kernel version

# =============================================================================
# COMPATIBLE LANGCHAIN ECOSYSTEM (MATCHING YOUR LANGCHAIN 0.3.10)
# =============================================================================
langchain-core>=0.3.0,<0.4.0     # Compatible with langchain 0.3.10
langchain-community>=0.3.0,<0.4.0 # Compatible with langchain 0.3.10
sentence-transformers==4.1.0
huggingface-hub==0.32.4                   # Hugging Face Hub for model sharing
langchain-huggingface==0.1.2           # Hugging Face integration for LangChain
# =============================================================================
# LLM PROVIDER INTEGRATIONS (COMPATIBLE VERSIONS)
# =============================================================================

# OpenAI (already have openai==1.68.2, adding LangChain integration)
langchain-openai>=0.2.0,<0.3.0   # Compatible with langchain 0.3.10

# Anthropic Claude
langchain-anthropic==0.3.0
anthropic>=0.34.0                 # Core Anthropic SDK

# Google Gemini  
langchain-google-genai>=2.0.0,<3.0.0
google-generativeai>=0.8.0       # Core Google SDK

# Groq (Ultra-fast inference)
langchain-groq>=0.2.0,<0.3.0
groq>=0.9.0                      # Core Groq SDK

# Mistral
langchain-mistralai>=0.2.0,<0.3.0
mistralai>=1.0.0                 # Core Mistral SDK

# Ollama (Local models - your DeepSeek R1!)
langchain-ollama>=0.2.0,<0.3.0

# =============================================================================
# UTILITIES & DISPLAY (COMPATIBLE VERSIONS)
# =============================================================================
requests>=2.31.0                 # HTTP requests (for Ollama health checks)
rich>=13.7.0                     # Beautiful terminal output
pandas>=2.0.0                    # Data manipulation
numpy>=1.24.0                    # Numerical computing

# =============================================================================
# COMPATIBILITY NOTES
# =============================================================================

# ‚úÖ WHAT'S COMPATIBLE:
# - Your existing Langflow 1.2.0 will work perfectly
# - Your existing LangChain 0.3.10 is supported
# - All new LLM providers use compatible versions
# - Your existing OpenAI setup continues working

# ‚ö†Ô∏è VERSION CONSTRAINTS:
# - Using version ranges to ensure compatibility
# - All LangChain extensions match your 0.3.x series
# - Provider SDKs use stable, tested versions

# üöÄ WHAT THIS ADDS:
# - DeepSeek integration (ultra-cheap $0.14/1M tokens)
# - Groq integration (ultra-fast sub-100ms)
# - Claude integration (premium quality)
# - Google Gemini integration (multimodal)
# - Mistral integration (European alternative)
# - Your local DeepSeek R1 support via Ollama

# =============================================================================
# INSTALLATION INSTRUCTIONS
# =============================================================================

# üîÑ UPGRADE YOUR EXISTING SETUP:
# 1. uv pip install -r requirements.txt
# 2. This will ADD new providers without breaking existing setup
# 3. Your Langflow and current workflows continue working
# 4. New LLM providers become available immediately

# üß™ TEST COMPATIBILITY:
# 1. After installation, test existing workflows first
# 2. Then test new providers: python -c "from src import quick_test; quick_test()"
# 3. Your local DeepSeek R1 should work immediately

# =============================================================================
# PROVIDER SETUP (API KEYS)
# =============================================================================

# üîë ADD TO YOUR .env FILE:
# DEEPSEEK_API_KEY=your_deepseek_key_here     # Ultra-cheap ($0.14/1M)
# GROQ_API_KEY=your_groq_key_here             # Ultra-fast (free tier)
# ANTHROPIC_API_KEY=your_anthropic_key_here   # Premium quality
# GOOGLE_API_KEY=your_google_key_here         # Multimodal
# MISTRAL_API_KEY=your_mistral_key_here       # European alternative

# Your existing OPENAI_API_KEY continues working as before

# =============================================================================
# WHAT WORKS IMMEDIATELY
# =============================================================================

# ‚úÖ WITHOUT ANY API KEYS:
# - Your local DeepSeek R1 via Ollama (completely free!)
# - All existing OpenAI workflows
# - All existing Langflow workflows

# ‚úÖ WITH DEEPSEEK API KEY ($0.14/1M):
# - Ultra-cheap cloud AI for scaling
# - 100x cost savings vs GPT-4
# - Perfect for learning and experimentation

# ‚úÖ WITH ALL PROVIDERS:
# - 25+ models across 8 providers
# - Smart model selection and optimization
# - Production-ready multi-provider architecture

# =============================================================================
# MIGRATION STRATEGY
# =============================================================================

# üéØ PHASE 1 (IMMEDIATE):
# pip install -r requirements.txt
# # Existing workflows continue working
# # Local DeepSeek R1 available immediately

# üéØ PHASE 2 (ADD ONE PROVIDER):
# Add DEEPSEEK_API_KEY to .env
# # Ultra-cheap cloud backup now available

# üéØ PHASE 3 (FULL SYSTEM):
# Add all desired API keys to .env
# # Complete multi-provider system ready

# =============================================================================
# TROUBLESHOOTING
# =============================================================================

# ‚ùå If you get version conflicts:
# 1. Create new virtual environment
# 2. pip install -r requirements.txt (fresh install)
# 3. Test existing workflows
# 4. Add new providers gradually

# ‚ùå If existing Langflow breaks:
# 1. The versions should be compatible
# 2. Check Langflow documentation for 1.2.0 compatibility
# 3. You can always revert to your original requirements.txt

# ‚ùå If new providers don't work:
# 1. Check API keys in .env file
# 2. Test internet connection
# 3. Try: python -c "from src import list_providers; list_providers()"

# =============================================================================
# BACKWARD COMPATIBILITY GUARANTEE
# =============================================================================

# üõ°Ô∏è SAFETY MEASURES:
# - All new packages use compatible version ranges
# - Your existing OpenAI/Langflow setup remains unchanged
# - You can test new providers without affecting existing work
# - Easy rollback if any issues occur

# üöÄ BENEFITS:
# - Keep all existing functionality
# - Add 100x cost savings with DeepSeek
# - Add ultra-fast inference with Groq
# - Add premium quality with Claude
# - Add your local DeepSeek R1 support

# Ready to upgrade your AI development to the next level! üéØ
