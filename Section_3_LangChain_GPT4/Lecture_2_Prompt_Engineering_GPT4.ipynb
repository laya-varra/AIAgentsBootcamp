{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93dcd7e6",
   "metadata": {},
   "source": [
    "# ‚úçÔ∏è Lecture 2: Prompt Engineering with GPT-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d574a19c",
   "metadata": {},
   "source": [
    "In this notebook, we‚Äôll explore how to write clear, structured prompts that get better responses from GPT-4.\n",
    "We‚Äôll use `PromptTemplate` from LangChain to frame user input effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df81f9a9",
   "metadata": {},
   "source": [
    "## üîê Step 1: Load OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e25ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf5afaf",
   "metadata": {},
   "source": [
    "## üì¶ Step 2: Import PromptTemplate and OpenAI LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b414bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f353a0f",
   "metadata": {},
   "source": [
    "## ‚úèÔ∏è Step 3: Design a specific prompt with constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce28473",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"Summarize {topic} in 20 words or less.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83381909",
   "metadata": {},
   "source": [
    "## üîó Step 4: Create the LangChain pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b2e40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(api_key=openai_api_key)\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41c26ea",
   "metadata": {},
   "source": [
    "## üöÄ Step 5: Try with a topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01159b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"topic\": \"Machine Learning\"})\n",
    "print(\"Response:\", response)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
