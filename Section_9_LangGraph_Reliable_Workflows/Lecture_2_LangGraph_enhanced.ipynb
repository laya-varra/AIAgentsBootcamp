{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4f0388b5",
      "metadata": {},
      "source": [
        "\n",
        "# Section 8, Lecture 2: Hands-on LangGraph: Build a Reliable AI Workflow for Business\n",
        "\n",
        "Welcome to Lecture 2 of Section 8! In the last lecture, we introduced LangGraph and saw how it can help you build reliable AI workflows. Now, we’re getting hands-on. In this notebook, you’ll create your own LangGraph workflow to automate a real-world business task: triaging customer support inquiries. By the end, you’ll have a working system that ensures reliability, saves time, and keeps your customers happy.\n",
        "\n",
        "### What You’ll Build\n",
        "- A LangGraph workflow with three nodes:\n",
        "  - **Classify Node**: Determines the inquiry type (e.g., question, complaint, urgent).\n",
        "  - **Route Node**: Decides where to send the inquiry (AI agent or human).\n",
        "  - **Respond Node**: Sends an AI response or flags for human review.\n",
        "- The workflow will include error handling (e.g., retries) to ensure reliability.\n",
        "\n",
        "### Why This Matters for Business\n",
        "Triaging customer support inquiries manually takes hours and risks delays. With LangGraph, you’ll automate this process with reliability, ensuring faster responses, fewer errors, and a better customer experience.\n",
        "\n",
        "Let’s get started!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "beb99450",
      "metadata": {},
      "source": [
        "## ⚙️ Step 1: Installing LangGraph\n",
        "\n",
        "Before we build anything, we need to make sure LangGraph is installed and ready to go.\n",
        "\n",
        "### 📦 What We're Doing:\n",
        "- Verifying whether the LangGraph package is installed in your environment.\n",
        "- If not installed, you’ll need to install it manually using:\n",
        "  ```bash\n",
        "  uv pip install langgraph\n",
        "  ```\n",
        "\n",
        "### 💼 Why This Matters:\n",
        "LangGraph is the backbone of your workflow automation—just like a project management system ensures every step gets done reliably.\n",
        "\n",
        "### 🛠️ Pro Tip:\n",
        "If you're not seeing a version output, double-check that your virtual environment is active and that you ran the install command in the terminal.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "09499a2f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ LangGraph is installed! Version: 0.3.30\n"
          ]
        }
      ],
      "source": [
        "# If you haven’t installed LangGraph yet, run this in your terminal (not here):\n",
        "# uv pip install langgraph\n",
        "# Make sure your virtual environment is activated:\n",
        "# Mac/Linux: source .venv/bin/activate\n",
        "# Windows: .venv\\Scripts\\Activate\n",
        "\n",
        "# Verify the installation\n",
        "try:\n",
        "    import langgraph\n",
        "    from importlib.metadata import version\n",
        "    print(\"✅ LangGraph is installed! Version:\", version(\"langgraph\"))\n",
        "except ImportError:\n",
        "    print(\"❌ LangGraph not found. Please install it using the command above.\")\n",
        "except Exception as e:\n",
        "    print(\"⚠️ An error occurred while checking version:\", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e777488",
      "metadata": {},
      "source": [
        "## 🔐 Step 2: Load Your OpenAI API Key\n",
        "\n",
        "To run intelligent workflows, we need GPT-4 to power decision-making. We’ll access it securely using your OpenAI API key.\n",
        "\n",
        "### 🧩 What We're Doing:\n",
        "- Loading the `.env` file that stores your API credentials.\n",
        "- Verifying that the key is accessible within the notebook.\n",
        "\n",
        "### 💼 Why This Matters:\n",
        "Securely storing and loading your API keys is a **best practice in real-world production systems**, where leaking keys can have cost and security implications.\n",
        "\n",
        "### 🛠️ Pro Tip:\n",
        "Your `.env` file should contain a line like this:\n",
        "`OPENAI_API_KEY=your-key-here`\n",
        "Never hardcode it directly into your script or notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "bde3b86b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API key loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Load the .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Get the API key\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Verify the key\n",
        "if openai_api_key:\n",
        "    print(\"API key loaded successfully!\")\n",
        "else:\n",
        "    print(\"API key not found. Make sure your .env file has OPENAI_API_KEY set.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "166f2f56",
      "metadata": {},
      "source": [
        "## 🧠 Step 3: Setting Up the LangGraph Workflow\n",
        "\n",
        "Let’s lay the foundation for your AI-powered customer support triage system by creating a LangGraph workflow.\n",
        "\n",
        "### 🧩 What We're Doing:\n",
        "- Creating a `StateGraph`, which lets us define and manage each step in the workflow.\n",
        "- Initializing the GPT-4 model as our language reasoning engine.\n",
        "- Creating a `WorkflowState` schema to store state across steps.\n",
        "\n",
        "### 💼 Why This Matters:\n",
        "In real business systems, each process must reliably move from one stage to another. LangGraph’s StateGraph ensures your flow is consistent and recoverable.\n",
        "\n",
        "### 📊 Real-World Use Case:\n",
        "Think of this like an automated ticket system—once set up, it guarantees tickets are never lost or stuck.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "060f18fd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Workflow set up successfully!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_openai import ChatOpenAI\n",
        "from typing import Dict, Any\n",
        "\n",
        "# Initialize the LLM (GPT-4)\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4\",\n",
        "    api_key=openai_api_key\n",
        ")\n",
        "\n",
        "# Define the state to track the workflow\n",
        "class WorkflowState(dict):\n",
        "    inquiry: str\n",
        "    inquiry_type: str\n",
        "    response: str\n",
        "    needs_human: bool\n",
        "\n",
        "# Create the workflow graph\n",
        "workflow = StateGraph(WorkflowState)\n",
        "\n",
        "print(\"Workflow set up successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d275de6",
      "metadata": {},
      "source": [
        "## 🔄 Step 4: Defining Nodes and Workflow Logic\n",
        "\n",
        "This is where your automation logic comes to life. Each **node** represents a step in the decision-making process.\n",
        "\n",
        "### 🤖 Node Roles:\n",
        "- **Classify Node**: Uses GPT-4 to label the inquiry.\n",
        "- **Route Node**: Decides whether to escalate or respond.\n",
        "- **Respond Node**: Drafts a reply or flags for human review.\n",
        "\n",
        "### 🔁 Flow Control:\n",
        "We connect nodes with **edges**, like arrows in a flowchart, that define how information flows from one step to another.\n",
        "\n",
        "### 🧩 Why It Matters:\n",
        "This level of structure is critical in systems where mistakes are costly—like customer complaints or legal queries. LangGraph ensures reliable, recoverable execution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "765e81a7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nodes and edges defined successfully!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Node 1: Classify the inquiry\n",
        "def classify_inquiry(state: WorkflowState) -> WorkflowState:\n",
        "    inquiry = state[\"inquiry\"]\n",
        "    prompt = f\"Classify this customer inquiry as a question, complaint, or urgent issue: {inquiry}\"\n",
        "    response = llm.invoke(prompt).content\n",
        "    state[\"inquiry_type\"] = response.lower()\n",
        "    return state\n",
        "\n",
        "# Node 2: Route the inquiry\n",
        "def route_inquiry(state: WorkflowState) -> WorkflowState:\n",
        "    inquiry_type = state[\"inquiry_type\"]\n",
        "    state[\"needs_human\"] = \"complaint\" in inquiry_type or \"urgent\" in inquiry_type\n",
        "    return state\n",
        "\n",
        "# Node 3: Respond or escalate\n",
        "def respond_or_escalate(state: WorkflowState) -> WorkflowState:\n",
        "    if state[\"needs_human\"]:\n",
        "        state[\"response\"] = \"Flagged for human review.\"\n",
        "    else:\n",
        "        prompt = f\"Draft a brief response to this customer inquiry: {state['inquiry']}\"\n",
        "        state[\"response\"] = llm.invoke(prompt).content\n",
        "    return state\n",
        "\n",
        "# Add nodes to the workflow\n",
        "workflow.add_node(\"classify\", classify_inquiry)\n",
        "workflow.add_node(\"route\", route_inquiry)\n",
        "workflow.add_node(\"respond\", respond_or_escalate)\n",
        "\n",
        "# Define edges (flow between nodes)\n",
        "workflow.set_entry_point(\"classify\")\n",
        "workflow.add_edge(\"classify\", \"route\")\n",
        "workflow.add_edge(\"route\", \"respond\")\n",
        "workflow.add_edge(\"respond\", END)\n",
        "\n",
        "# Compile the workflow\n",
        "app = workflow.compile()\n",
        "\n",
        "print(\"Nodes and edges defined successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f5ac193",
      "metadata": {},
      "source": [
        "## 🚀 Step 5: Running the Workflow\n",
        "\n",
        "Now let’s run your LangGraph pipeline on a **real-world inquiry**: “My order is delayed—what’s going on?”\n",
        "\n",
        "### 🧪 What Happens:\n",
        "1. The inquiry is classified (e.g., as a complaint).\n",
        "2. The system routes it to either an agent or flags it.\n",
        "3. A response is generated or it's escalated to a human.\n",
        "\n",
        "### 💼 Why This Matters:\n",
        "You just built a reliable triage bot—imagine deploying this inside Zendesk or Freshdesk. It ensures **zero tickets fall through the cracks**.\n",
        "\n",
        "### ✏️ Try This:\n",
        "Replace the sample inquiry with something like “I want to cancel my subscription” and see how the flow adapts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "93e89c9b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Output:\n",
            " Dear Customer,\n",
            "\n",
            "We sincerely apologize for the delay in your order. We understand how frustrating this can be. Upon checking, we found that there has been an unexpected delay in our supply chain which has affected the delivery of some orders. We are working tirelessly to resolve this issue and get your order to you as soon as possible. We appreciate your patience and understanding during this time.\n",
            "\n",
            "Best regards,\n",
            "[Your Name]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "initial_state = WorkflowState(\n",
        "    inquiry=\"My order is delayed—what’s going on?\",\n",
        "    inquiry_type=\"\",\n",
        "    response=\"\",\n",
        "    needs_human=False\n",
        ")\n",
        "\n",
        "result = app.invoke(initial_state)\n",
        "\n",
        "# Print the final output\n",
        "print(\"Final Output:\\n\", result[\"response\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fbe7806",
      "metadata": {},
      "source": [
        "## 🎓 Wrap-Up and What’s Next\n",
        "\n",
        "Congratulations! You’ve just built your **first reliable AI workflow using LangGraph**.\n",
        "\n",
        "### 💡 What You Built:\n",
        "- A structured graph with intelligent steps (nodes).\n",
        "- A decision-making pipeline with GPT-4.\n",
        "- A workflow that can **scale, retry, and never miss a beat**.\n",
        "\n",
        "### 🧠 Reflect:\n",
        "- How could this apply in your business?\n",
        "- Could you use a similar flow for onboarding, refunds, or lead scoring?\n",
        "\n",
        "### 👉 Next:\n",
        "In the next lecture, we’ll enhance this with **memory and branching logic**, enabling smarter decisions based on past interactions.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
